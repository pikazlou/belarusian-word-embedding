{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7b8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc6904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logging initialized\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, force = True)\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Logging initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9fc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "class Callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_list.append(loss)\n",
    "        logger.info('Loss after epoch {}:{}'.format(self.epoch, loss))\n",
    "        model.running_training_loss = 0.0\n",
    "        self.epoch = self.epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e8337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.025>', 'datetime': '2023-05-19T15:41:51.796103', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sg=1, vector_size=100, window=3, min_count=10, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35054bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence('processed-corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615cf92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #5000000, processed 40831628 words, keeping 101552 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000000, processed 81753225 words, keeping 114802 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #15000000, processed 122575037 words, keeping 122333 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000000, processed 163439274 words, keeping 127317 word types\n",
      "INFO:gensim.models.word2vec:collected 130029 word types from a corpus of 191558143 raw words and 23453583 sentences\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 79373 unique words (61.04% of original 130029, drops 50656)', 'datetime': '2023-05-19T15:43:08.605477', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 191387939 word corpus (99.91% of original 191558143, drops 170204)', 'datetime': '2023-05-19T15:43:08.606170', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 130029 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 16 most-common words\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 185893234.09818068 word corpus (97.1%% of prior 191387939)', 'datetime': '2023-05-19T15:43:08.883678', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:estimated required memory for 79373 words and 100 dimensions: 103184900 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-05-19T15:43:09.416682', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences, progress_per=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867dc13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 5 workers on 79373 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=3 shrink_windows=True', 'datetime': '2023-05-19T15:43:09.423833', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 0.51% examples, 937538 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 0: training on 191558143 raw words (185889644 effective words) took 177.6s, 1046906 effective words/s\n",
      "INFO:root:Loss after epoch 0:65791416.0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 0.53% examples, 974067 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1: training on 191558143 raw words (185893121 effective words) took 176.4s, 1053781 effective words/s\n",
      "INFO:root:Loss after epoch 1:67453424.0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 0.54% examples, 992942 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2: training on 191558143 raw words (185892830 effective words) took 177.1s, 1049939 effective words/s\n",
      "INFO:root:Loss after epoch 2:67744288.0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 0.51% examples, 937576 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3: training on 191558143 raw words (185891419 effective words) took 175.0s, 1062345 effective words/s\n",
      "INFO:root:Loss after epoch 3:67989224.0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 0.57% examples, 1048240 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4: training on 191558143 raw words (185893309 effective words) took 174.5s, 1065003 effective words/s\n",
      "INFO:root:Loss after epoch 4:68209808.0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 0.55% examples, 1019877 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5: training on 191558143 raw words (185895529 effective words) took 172.3s, 1079056 effective words/s\n",
      "INFO:root:Loss after epoch 5:68408736.0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 0.54% examples, 994605 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6: training on 191558143 raw words (185892855 effective words) took 172.1s, 1080282 effective words/s\n",
      "INFO:root:Loss after epoch 6:68563840.0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 0.55% examples, 1007333 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7: training on 191558143 raw words (185895443 effective words) took 172.4s, 1078592 effective words/s\n",
      "INFO:root:Loss after epoch 7:68730808.0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 0.56% examples, 1045299 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8: training on 191558143 raw words (185894614 effective words) took 171.6s, 1083344 effective words/s\n",
      "INFO:root:Loss after epoch 8:68886352.0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 0.56% examples, 1037166 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9: training on 191558143 raw words (185891980 effective words) took 172.1s, 1079925 effective words/s\n",
      "INFO:root:Loss after epoch 9:68989544.0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 0.56% examples, 1029610 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10: training on 191558143 raw words (185893455 effective words) took 181.1s, 1026471 effective words/s\n",
      "INFO:root:Loss after epoch 10:69111104.0\n",
      "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 0.55% examples, 1016514 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 11: training on 191558143 raw words (185892409 effective words) took 181.7s, 1022969 effective words/s\n",
      "INFO:root:Loss after epoch 11:69213656.0\n",
      "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 0.53% examples, 975224 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 12: training on 191558143 raw words (185893379 effective words) took 179.8s, 1033919 effective words/s\n",
      "INFO:root:Loss after epoch 12:69296536.0\n",
      "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 0.54% examples, 997804 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 13: training on 191558143 raw words (185892802 effective words) took 183.3s, 1013977 effective words/s\n",
      "INFO:root:Loss after epoch 13:69352920.0\n",
      "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 0.52% examples, 962029 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 14: training on 191558143 raw words (185893706 effective words) took 180.3s, 1030779 effective words/s\n",
      "INFO:root:Loss after epoch 14:69457472.0\n",
      "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 0.53% examples, 974452 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 15: training on 191558143 raw words (185894867 effective words) took 179.9s, 1033517 effective words/s\n",
      "INFO:root:Loss after epoch 15:69556248.0\n",
      "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 0.54% examples, 976958 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 16: training on 191558143 raw words (185891727 effective words) took 180.4s, 1030726 effective words/s\n",
      "INFO:root:Loss after epoch 16:69598128.0\n",
      "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 0.57% examples, 1048436 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 17: training on 191558143 raw words (185893100 effective words) took 178.9s, 1038857 effective words/s\n",
      "INFO:root:Loss after epoch 17:69660176.0\n",
      "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 0.54% examples, 919498 words/s, in_qsize 6, out_qsize 4\n",
      "INFO:gensim.models.word2vec:EPOCH 18: training on 191558143 raw words (185893396 effective words) took 178.7s, 1040479 effective words/s\n",
      "INFO:root:Loss after epoch 18:69698224.0\n",
      "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 0.55% examples, 1023263 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 19: training on 191558143 raw words (185894147 effective words) took 174.8s, 1063662 effective words/s\n",
      "INFO:root:Loss after epoch 19:69736472.0\n",
      "INFO:gensim.models.word2vec:EPOCH 20 - PROGRESS: at 0.54% examples, 993879 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 20: training on 191558143 raw words (185894240 effective words) took 175.2s, 1060842 effective words/s\n",
      "INFO:root:Loss after epoch 20:69797440.0\n",
      "INFO:gensim.models.word2vec:EPOCH 21 - PROGRESS: at 0.55% examples, 1017948 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 21: training on 191558143 raw words (185891638 effective words) took 174.6s, 1064856 effective words/s\n",
      "INFO:root:Loss after epoch 21:69853080.0\n",
      "INFO:gensim.models.word2vec:EPOCH 22 - PROGRESS: at 0.55% examples, 1011339 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 22: training on 191558143 raw words (185891365 effective words) took 171.5s, 1083643 effective words/s\n",
      "INFO:root:Loss after epoch 22:69867464.0\n",
      "INFO:gensim.models.word2vec:EPOCH 23 - PROGRESS: at 0.55% examples, 1027101 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 23: training on 191558143 raw words (185893541 effective words) took 173.9s, 1068693 effective words/s\n",
      "INFO:root:Loss after epoch 23:69902280.0\n",
      "INFO:gensim.models.word2vec:EPOCH 24 - PROGRESS: at 0.56% examples, 981454 words/s, in_qsize 6, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 24: training on 191558143 raw words (185890998 effective words) took 183.6s, 1012439 effective words/s\n",
      "INFO:root:Loss after epoch 24:69991312.0\n",
      "INFO:gensim.models.word2vec:EPOCH 25 - PROGRESS: at 0.54% examples, 994255 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 25: training on 191558143 raw words (185896002 effective words) took 181.3s, 1025408 effective words/s\n",
      "INFO:root:Loss after epoch 25:70013192.0\n",
      "INFO:gensim.models.word2vec:EPOCH 26 - PROGRESS: at 0.55% examples, 1026532 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 26: training on 191558143 raw words (185893213 effective words) took 174.9s, 1062622 effective words/s\n",
      "INFO:root:Loss after epoch 26:70048872.0\n",
      "INFO:gensim.models.word2vec:EPOCH 27 - PROGRESS: at 0.54% examples, 993381 words/s, in_qsize 9, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 27: training on 191558143 raw words (185893606 effective words) took 184.6s, 1007127 effective words/s\n",
      "INFO:root:Loss after epoch 27:70063656.0\n",
      "INFO:gensim.models.word2vec:EPOCH 28 - PROGRESS: at 0.53% examples, 977756 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 28: training on 191558143 raw words (185892911 effective words) took 180.2s, 1031863 effective words/s\n",
      "INFO:root:Loss after epoch 28:70089896.0\n",
      "INFO:gensim.models.word2vec:EPOCH 29 - PROGRESS: at 0.56% examples, 1027222 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 29: training on 191558143 raw words (185893452 effective words) took 173.7s, 1070499 effective words/s\n",
      "INFO:root:Loss after epoch 29:70129952.0\n",
      "INFO:gensim.models.word2vec:EPOCH 30 - PROGRESS: at 0.55% examples, 1017987 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 30: training on 191558143 raw words (185894732 effective words) took 174.6s, 1064818 effective words/s\n",
      "INFO:root:Loss after epoch 30:70138520.0\n",
      "INFO:gensim.models.word2vec:EPOCH 31 - PROGRESS: at 0.55% examples, 1019468 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 31: training on 191558143 raw words (185895135 effective words) took 173.1s, 1073862 effective words/s\n",
      "INFO:root:Loss after epoch 31:70160968.0\n",
      "INFO:gensim.models.word2vec:EPOCH 32 - PROGRESS: at 0.55% examples, 1014250 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 32: training on 191558143 raw words (185892337 effective words) took 178.7s, 1040475 effective words/s\n",
      "INFO:root:Loss after epoch 32:70168368.0\n",
      "INFO:gensim.models.word2vec:EPOCH 33 - PROGRESS: at 0.56% examples, 1021383 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 33: training on 191558143 raw words (185894445 effective words) took 181.0s, 1027021 effective words/s\n",
      "INFO:root:Loss after epoch 33:70179928.0\n",
      "INFO:gensim.models.word2vec:EPOCH 34 - PROGRESS: at 0.54% examples, 995494 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 34: training on 191558143 raw words (185894910 effective words) took 185.9s, 1000006 effective words/s\n",
      "INFO:root:Loss after epoch 34:70254864.0\n",
      "INFO:gensim.models.word2vec:EPOCH 35 - PROGRESS: at 0.52% examples, 966010 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 35: training on 191558143 raw words (185895929 effective words) took 185.0s, 1004813 effective words/s\n",
      "INFO:root:Loss after epoch 35:70273368.0\n",
      "INFO:gensim.models.word2vec:EPOCH 36 - PROGRESS: at 0.51% examples, 929959 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 36: training on 191558143 raw words (185891868 effective words) took 182.6s, 1017927 effective words/s\n",
      "INFO:root:Loss after epoch 36:70273880.0\n",
      "INFO:gensim.models.word2vec:EPOCH 37 - PROGRESS: at 0.57% examples, 1031372 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 37: training on 191558143 raw words (185891530 effective words) took 174.6s, 1064437 effective words/s\n",
      "INFO:root:Loss after epoch 37:70302544.0\n",
      "INFO:gensim.models.word2vec:EPOCH 38 - PROGRESS: at 0.54% examples, 1006977 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 38: training on 191558143 raw words (185891568 effective words) took 178.8s, 1039891 effective words/s\n",
      "INFO:root:Loss after epoch 38:70317008.0\n",
      "INFO:gensim.models.word2vec:EPOCH 39 - PROGRESS: at 0.49% examples, 890162 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 39: training on 191558143 raw words (185894994 effective words) took 175.2s, 1061147 effective words/s\n",
      "INFO:root:Loss after epoch 39:70292712.0\n",
      "INFO:gensim.models.word2vec:EPOCH 40 - PROGRESS: at 0.54% examples, 945999 words/s, in_qsize 7, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 40: training on 191558143 raw words (185893181 effective words) took 183.9s, 1010947 effective words/s\n",
      "INFO:root:Loss after epoch 40:70351136.0\n",
      "INFO:gensim.models.word2vec:EPOCH 41 - PROGRESS: at 0.54% examples, 979242 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 41: training on 191558143 raw words (185893627 effective words) took 177.3s, 1048231 effective words/s\n",
      "INFO:root:Loss after epoch 41:70361944.0\n",
      "INFO:gensim.models.word2vec:EPOCH 42 - PROGRESS: at 0.55% examples, 1019096 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 42: training on 191558143 raw words (185891722 effective words) took 174.5s, 1064977 effective words/s\n",
      "INFO:root:Loss after epoch 42:70404072.0\n",
      "INFO:gensim.models.word2vec:EPOCH 43 - PROGRESS: at 0.54% examples, 996858 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 43: training on 191558143 raw words (185892454 effective words) took 175.1s, 1061423 effective words/s\n",
      "INFO:root:Loss after epoch 43:70377768.0\n",
      "INFO:gensim.models.word2vec:EPOCH 44 - PROGRESS: at 0.55% examples, 1025021 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 44: training on 191558143 raw words (185893820 effective words) took 171.3s, 1085510 effective words/s\n",
      "INFO:root:Loss after epoch 44:70433008.0\n",
      "INFO:gensim.models.word2vec:EPOCH 45 - PROGRESS: at 0.55% examples, 1008571 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 45: training on 191558143 raw words (185894394 effective words) took 174.6s, 1064954 effective words/s\n",
      "INFO:root:Loss after epoch 45:70423672.0\n",
      "INFO:gensim.models.word2vec:EPOCH 46 - PROGRESS: at 0.55% examples, 1009962 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 46: training on 191558143 raw words (185893472 effective words) took 172.0s, 1080655 effective words/s\n",
      "INFO:root:Loss after epoch 46:70435840.0\n",
      "INFO:gensim.models.word2vec:EPOCH 47 - PROGRESS: at 0.55% examples, 1012297 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 47: training on 191558143 raw words (185895728 effective words) took 171.4s, 1084792 effective words/s\n",
      "INFO:root:Loss after epoch 47:70446744.0\n",
      "INFO:gensim.models.word2vec:EPOCH 48 - PROGRESS: at 0.55% examples, 1021957 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 48: training on 191558143 raw words (185895369 effective words) took 174.9s, 1063078 effective words/s\n",
      "INFO:root:Loss after epoch 48:70442448.0\n",
      "INFO:gensim.models.word2vec:EPOCH 49 - PROGRESS: at 0.54% examples, 1001386 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 49: training on 191558143 raw words (185894674 effective words) took 173.0s, 1074333 effective words/s\n",
      "INFO:root:Loss after epoch 49:70455936.0\n",
      "INFO:gensim.models.word2vec:EPOCH 50 - PROGRESS: at 0.54% examples, 1003340 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 50: training on 191558143 raw words (185893788 effective words) took 180.2s, 1031435 effective words/s\n",
      "INFO:root:Loss after epoch 50:70482664.0\n",
      "INFO:gensim.models.word2vec:EPOCH 51 - PROGRESS: at 0.52% examples, 921905 words/s, in_qsize 9, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 51: training on 191558143 raw words (185891967 effective words) took 177.1s, 1049395 effective words/s\n",
      "INFO:root:Loss after epoch 51:70485312.0\n",
      "INFO:gensim.models.word2vec:EPOCH 52 - PROGRESS: at 0.54% examples, 998080 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 52: training on 191558143 raw words (185891964 effective words) took 179.7s, 1034669 effective words/s\n",
      "INFO:root:Loss after epoch 52:70488856.0\n",
      "INFO:gensim.models.word2vec:EPOCH 53 - PROGRESS: at 0.55% examples, 959228 words/s, in_qsize 7, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 53: training on 191558143 raw words (185893124 effective words) took 177.8s, 1045259 effective words/s\n",
      "INFO:root:Loss after epoch 53:70477840.0\n",
      "INFO:gensim.models.word2vec:EPOCH 54 - PROGRESS: at 0.55% examples, 1022490 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 54: training on 191558143 raw words (185890780 effective words) took 176.5s, 1053106 effective words/s\n",
      "INFO:root:Loss after epoch 54:70510648.0\n",
      "INFO:gensim.models.word2vec:EPOCH 55 - PROGRESS: at 0.55% examples, 1022011 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 55: training on 191558143 raw words (185893156 effective words) took 177.5s, 1047392 effective words/s\n",
      "INFO:root:Loss after epoch 55:70547192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 56 - PROGRESS: at 0.55% examples, 1015424 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 56: training on 191558143 raw words (185892750 effective words) took 180.8s, 1027935 effective words/s\n",
      "INFO:root:Loss after epoch 56:70534584.0\n",
      "INFO:gensim.models.word2vec:EPOCH 57 - PROGRESS: at 0.50% examples, 913385 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 57: training on 191558143 raw words (185893404 effective words) took 182.5s, 1018554 effective words/s\n",
      "INFO:root:Loss after epoch 57:70544992.0\n",
      "INFO:gensim.models.word2vec:EPOCH 58 - PROGRESS: at 0.49% examples, 899245 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 58: training on 191558143 raw words (185892525 effective words) took 191.1s, 972497 effective words/s\n",
      "INFO:root:Loss after epoch 58:70549184.0\n",
      "INFO:gensim.models.word2vec:EPOCH 59 - PROGRESS: at 0.49% examples, 905463 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 59: training on 191558143 raw words (185894577 effective words) took 196.2s, 947540 effective words/s\n",
      "INFO:root:Loss after epoch 59:70558360.0\n",
      "INFO:gensim.models.word2vec:EPOCH 60 - PROGRESS: at 0.55% examples, 1013010 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 60: training on 191558143 raw words (185893977 effective words) took 178.1s, 1043583 effective words/s\n",
      "INFO:root:Loss after epoch 60:70537240.0\n",
      "INFO:gensim.models.word2vec:EPOCH 61 - PROGRESS: at 0.54% examples, 973910 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 61: training on 191558143 raw words (185892483 effective words) took 176.6s, 1052388 effective words/s\n",
      "INFO:root:Loss after epoch 61:70571176.0\n",
      "INFO:gensim.models.word2vec:EPOCH 62 - PROGRESS: at 0.52% examples, 967895 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 62: training on 191558143 raw words (185893542 effective words) took 176.7s, 1052203 effective words/s\n",
      "INFO:root:Loss after epoch 62:70584784.0\n",
      "INFO:gensim.models.word2vec:EPOCH 63 - PROGRESS: at 0.53% examples, 974004 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 63: training on 191558143 raw words (185893813 effective words) took 176.5s, 1053120 effective words/s\n",
      "INFO:root:Loss after epoch 63:70581984.0\n",
      "INFO:gensim.models.word2vec:EPOCH 64 - PROGRESS: at 0.53% examples, 975609 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 64: training on 191558143 raw words (185894804 effective words) took 176.2s, 1055219 effective words/s\n",
      "INFO:root:Loss after epoch 64:70580888.0\n",
      "INFO:gensim.models.word2vec:EPOCH 65 - PROGRESS: at 0.52% examples, 965981 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 65: training on 191558143 raw words (185893806 effective words) took 176.6s, 1052820 effective words/s\n",
      "INFO:root:Loss after epoch 65:70607192.0\n",
      "INFO:gensim.models.word2vec:EPOCH 66 - PROGRESS: at 0.54% examples, 1001068 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 66: training on 191558143 raw words (185895242 effective words) took 177.7s, 1045935 effective words/s\n",
      "INFO:root:Loss after epoch 66:70624256.0\n",
      "INFO:gensim.models.word2vec:EPOCH 67 - PROGRESS: at 0.51% examples, 928984 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 67: training on 191558143 raw words (185895009 effective words) took 178.0s, 1044236 effective words/s\n",
      "INFO:root:Loss after epoch 67:70584552.0\n",
      "INFO:gensim.models.word2vec:EPOCH 68 - PROGRESS: at 0.57% examples, 975376 words/s, in_qsize 10, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 68: training on 191558143 raw words (185894981 effective words) took 175.4s, 1059747 effective words/s\n",
      "INFO:root:Loss after epoch 68:70583584.0\n",
      "INFO:gensim.models.word2vec:EPOCH 69 - PROGRESS: at 0.54% examples, 1001744 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 69: training on 191558143 raw words (185892861 effective words) took 175.5s, 1059321 effective words/s\n",
      "INFO:root:Loss after epoch 69:70671808.0\n",
      "INFO:gensim.models.word2vec:EPOCH 70 - PROGRESS: at 0.56% examples, 1042658 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 70: training on 191558143 raw words (185892754 effective words) took 176.5s, 1053146 effective words/s\n",
      "INFO:root:Loss after epoch 70:70622712.0\n",
      "INFO:gensim.models.word2vec:EPOCH 71 - PROGRESS: at 0.56% examples, 1031416 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 71: training on 191558143 raw words (185895100 effective words) took 173.9s, 1069077 effective words/s\n",
      "INFO:root:Loss after epoch 71:70639200.0\n",
      "INFO:gensim.models.word2vec:EPOCH 72 - PROGRESS: at 0.52% examples, 912864 words/s, in_qsize 6, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 72: training on 191558143 raw words (185891241 effective words) took 176.0s, 1056423 effective words/s\n",
      "INFO:root:Loss after epoch 72:70651712.0\n",
      "INFO:gensim.models.word2vec:EPOCH 73 - PROGRESS: at 0.56% examples, 1036964 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 73: training on 191558143 raw words (185892917 effective words) took 172.8s, 1075991 effective words/s\n",
      "INFO:root:Loss after epoch 73:70646536.0\n",
      "INFO:gensim.models.word2vec:EPOCH 74 - PROGRESS: at 0.56% examples, 1038517 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 74: training on 191558143 raw words (185892677 effective words) took 172.9s, 1074897 effective words/s\n",
      "INFO:root:Loss after epoch 74:70638984.0\n",
      "INFO:gensim.models.word2vec:EPOCH 75 - PROGRESS: at 0.54% examples, 980158 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 75: training on 191558143 raw words (185893848 effective words) took 174.3s, 1066285 effective words/s\n",
      "INFO:root:Loss after epoch 75:70661128.0\n",
      "INFO:gensim.models.word2vec:EPOCH 76 - PROGRESS: at 0.55% examples, 1015343 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 76: training on 191558143 raw words (185892184 effective words) took 176.5s, 1053398 effective words/s\n",
      "INFO:root:Loss after epoch 76:70666504.0\n",
      "INFO:gensim.models.word2vec:EPOCH 77 - PROGRESS: at 0.56% examples, 1034341 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 77: training on 191558143 raw words (185893772 effective words) took 173.7s, 1070170 effective words/s\n",
      "INFO:root:Loss after epoch 77:70677048.0\n",
      "INFO:gensim.models.word2vec:EPOCH 78 - PROGRESS: at 0.54% examples, 1003234 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 78: training on 191558143 raw words (185894352 effective words) took 174.2s, 1066934 effective words/s\n",
      "INFO:root:Loss after epoch 78:70649696.0\n",
      "INFO:gensim.models.word2vec:EPOCH 79 - PROGRESS: at 0.56% examples, 1030197 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 79: training on 191558143 raw words (185894867 effective words) took 175.5s, 1059339 effective words/s\n",
      "INFO:root:Loss after epoch 79:70654008.0\n",
      "INFO:gensim.models.word2vec:EPOCH 80 - PROGRESS: at 0.54% examples, 1001854 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 80: training on 191558143 raw words (185893686 effective words) took 182.5s, 1018866 effective words/s\n",
      "INFO:root:Loss after epoch 80:70654376.0\n",
      "INFO:gensim.models.word2vec:EPOCH 81 - PROGRESS: at 0.52% examples, 947803 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 81: training on 191558143 raw words (185891401 effective words) took 183.8s, 1011268 effective words/s\n",
      "INFO:root:Loss after epoch 81:70684456.0\n",
      "INFO:gensim.models.word2vec:EPOCH 82 - PROGRESS: at 0.54% examples, 993281 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 82: training on 191558143 raw words (185894121 effective words) took 182.4s, 1019006 effective words/s\n",
      "INFO:root:Loss after epoch 82:70704792.0\n",
      "INFO:gensim.models.word2vec:EPOCH 83 - PROGRESS: at 0.57% examples, 1049107 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 83: training on 191558143 raw words (185894063 effective words) took 176.0s, 1056204 effective words/s\n",
      "INFO:root:Loss after epoch 83:70704528.0\n",
      "INFO:gensim.models.word2vec:EPOCH 84 - PROGRESS: at 0.54% examples, 919085 words/s, in_qsize 10, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 84: training on 191558143 raw words (185896557 effective words) took 177.1s, 1049820 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loss after epoch 84:70699360.0\n",
      "INFO:gensim.models.word2vec:EPOCH 85 - PROGRESS: at 0.54% examples, 981716 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 85: training on 191558143 raw words (185893900 effective words) took 176.2s, 1055165 effective words/s\n",
      "INFO:root:Loss after epoch 85:70669800.0\n",
      "INFO:gensim.models.word2vec:EPOCH 86 - PROGRESS: at 0.55% examples, 1014866 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 86: training on 191558143 raw words (185893945 effective words) took 175.9s, 1057060 effective words/s\n",
      "INFO:root:Loss after epoch 86:70698088.0\n",
      "INFO:gensim.models.word2vec:EPOCH 87 - PROGRESS: at 0.55% examples, 1015785 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 87: training on 191558143 raw words (185894493 effective words) took 176.0s, 1056444 effective words/s\n",
      "INFO:root:Loss after epoch 87:70704976.0\n",
      "INFO:gensim.models.word2vec:EPOCH 88 - PROGRESS: at 0.54% examples, 1004394 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 88: training on 191558143 raw words (185895023 effective words) took 175.9s, 1056954 effective words/s\n",
      "INFO:root:Loss after epoch 88:70685928.0\n",
      "INFO:gensim.models.word2vec:EPOCH 89 - PROGRESS: at 0.54% examples, 985193 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 89: training on 191558143 raw words (185891131 effective words) took 181.3s, 1025563 effective words/s\n",
      "INFO:root:Loss after epoch 89:70695840.0\n",
      "INFO:gensim.models.word2vec:EPOCH 90 - PROGRESS: at 0.55% examples, 1010987 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 90: training on 191558143 raw words (185895838 effective words) took 172.0s, 1080990 effective words/s\n",
      "INFO:root:Loss after epoch 90:70697904.0\n",
      "INFO:gensim.models.word2vec:EPOCH 91 - PROGRESS: at 0.54% examples, 992652 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 91: training on 191558143 raw words (185891391 effective words) took 172.3s, 1078689 effective words/s\n",
      "INFO:root:Loss after epoch 91:70700480.0\n",
      "INFO:gensim.models.word2vec:EPOCH 92 - PROGRESS: at 0.58% examples, 1062898 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 92: training on 191558143 raw words (185894172 effective words) took 174.3s, 1066583 effective words/s\n",
      "INFO:root:Loss after epoch 92:70704432.0\n",
      "INFO:gensim.models.word2vec:EPOCH 93 - PROGRESS: at 0.58% examples, 1053272 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 93: training on 191558143 raw words (185894544 effective words) took 175.8s, 1057645 effective words/s\n",
      "INFO:root:Loss after epoch 93:70720112.0\n",
      "INFO:gensim.models.word2vec:EPOCH 94 - PROGRESS: at 0.56% examples, 958753 words/s, in_qsize 10, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 94: training on 191558143 raw words (185894125 effective words) took 172.4s, 1078585 effective words/s\n",
      "INFO:root:Loss after epoch 94:70695824.0\n",
      "INFO:gensim.models.word2vec:EPOCH 95 - PROGRESS: at 0.54% examples, 987778 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 95: training on 191558143 raw words (185894600 effective words) took 172.7s, 1076614 effective words/s\n",
      "INFO:root:Loss after epoch 95:70712240.0\n",
      "INFO:gensim.models.word2vec:EPOCH 96 - PROGRESS: at 0.57% examples, 1052098 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 96: training on 191558143 raw words (185893765 effective words) took 174.0s, 1068073 effective words/s\n",
      "INFO:root:Loss after epoch 96:70715752.0\n",
      "INFO:gensim.models.word2vec:EPOCH 97 - PROGRESS: at 0.36% examples, 657520 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 97: training on 191558143 raw words (185896620 effective words) took 174.0s, 1068517 effective words/s\n",
      "INFO:root:Loss after epoch 97:70680200.0\n",
      "INFO:gensim.models.word2vec:EPOCH 98 - PROGRESS: at 0.54% examples, 985310 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 98: training on 191558143 raw words (185892393 effective words) took 172.4s, 1078039 effective words/s\n",
      "INFO:root:Loss after epoch 98:70716992.0\n",
      "INFO:gensim.models.word2vec:EPOCH 99 - PROGRESS: at 0.54% examples, 1004250 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 99: training on 191558143 raw words (185891941 effective words) took 171.3s, 1085214 effective words/s\n",
      "INFO:root:Loss after epoch 99:70682640.0\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 19155814300 raw words (18589350561 effective words) took 17702.7s, 1050089 effective words/s', 'datetime': '2023-05-19T21:45:51.177520', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18589350561, 19155814300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we override alpha with small values, since default values result in poor train performance. See loss plot below\n",
    "model.train(sentences, epochs=100, start_alpha=0.0001, end_alpha=0.00001, total_examples=model.corpus_count, total_words=model.corpus_total_words, compute_loss=True, report_delay=300, callbacks=[Callback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e1b267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x177f1d090>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47482d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кошка', 0.8314971923828125),\n",
       " ('котка', 0.799300491809845),\n",
       " ('жывёліна', 0.7933835387229919),\n",
       " ('кот', 0.7918497323989868),\n",
       " ('сабачка', 0.7706744074821472),\n",
       " ('кацяня', 0.760342001914978),\n",
       " ('звер', 0.7451285719871521),\n",
       " ('дзік', 0.7436728477478027),\n",
       " ('мядзведзь', 0.7309896349906921),\n",
       " ('малпа', 0.7297574877738953),\n",
       " ('лісіца', 0.7211086750030518),\n",
       " ('конь', 0.7209383845329285),\n",
       " ('пацук', 0.7193618416786194),\n",
       " ('бык', 0.7151439189910889),\n",
       " ('муха', 0.7126638889312744),\n",
       " ('драпежнік', 0.7105709314346313),\n",
       " ('каза', 0.7051055431365967),\n",
       " ('асёл', 0.7039604783058167),\n",
       " ('пародзісты', 0.6996980905532837),\n",
       " ('бомж', 0.6990068554878235)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('сабака', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0090e873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['быць',\n",
       " 'год',\n",
       " 'беларускі',\n",
       " 'беларусь',\n",
       " 'чалавек',\n",
       " 'магчы',\n",
       " 'час',\n",
       " 'усё',\n",
       " 'дзень',\n",
       " 'большыць']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec534c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname_or_handle': 'word2vec-cc100-skipgram-d100-w3-min10.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-05-19T21:45:51.693746', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'saving'}\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "INFO:gensim.utils:saved word2vec-cc100-skipgram-d100-w3-min10.model\n"
     ]
    }
   ],
   "source": [
    "model.save(\"word2vec-cc100-skipgram-d100-w3-min10.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "389e42e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:storing 79373x100 projection weights into word2vec-cc100-skipgram-d100-w3-min10.vectors\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('word2vec-cc100-skipgram-d100-w3-min10.vectors')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
