{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7b8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_short, strip_numeric, strip_multiple_whitespaces, remove_stopwords\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import lzma\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc6904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logging initialized\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, force = True)\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Logging initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d69008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GrammarDB.zip', <http.client.HTTPMessage at 0x174669610>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Link found here: https://metatext.io/datasets/cc100-belarusian\n",
    "urllib.request.urlretrieve('https://data.statmt.org/cc-100/be.txt.xz', \n",
    "                           'be.txt.xz')\n",
    "\n",
    "urllib.request.urlretrieve('https://github.com/Belarus/GrammarDB/archive/refs/tags/PUBLICATION_2021.zip', \n",
    "                           'GrammarDB.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f66982",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lzma.open(\"be.txt.xz\", \"rb\") as fsrc:\n",
    "    with open(\"be.txt\", \"wb\") as fdst:\n",
    "        shutil.copyfileobj(fsrc, fdst)\n",
    "\n",
    "with zipfile.ZipFile('GrammarDB.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49326e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "from itertools import islice\n",
    "\n",
    "def calculate_mapping_from_forms_to_base(filepath):\n",
    "    xml_doc = xml.dom.minidom.parse(filepath)\n",
    "    words = xml_doc.getElementsByTagName('Variant')\n",
    "    result = {}\n",
    "    collision_count = 0\n",
    "    collisions = set()\n",
    "    for word in words:\n",
    "        base = word.getAttribute('lemma').replace(\"+\", \"\").lower()\n",
    "        forms_objs = word.getElementsByTagName('Form')\n",
    "        local_map = {}\n",
    "        citation_count = max([forms_obj.getAttribute('slouniki').count(',') for forms_obj in forms_objs]) + 1\n",
    "        for forms_obj in forms_objs:\n",
    "            if len(forms_obj.childNodes) > 0:\n",
    "                form = forms_obj.childNodes[0].data.replace(\"+\", \"\").lower()\n",
    "                local_map[form] = (base, citation_count)\n",
    "        for k, v in local_map.items():\n",
    "            if k in result:\n",
    "                if result[k][1] == v[1] and result[k][0] != v[0]:\n",
    "                    collision_count += 1\n",
    "                    collisions.add(v[0])\n",
    "                    collisions.add(result[k][0])\n",
    "                elif result[k][1] < v[1]:\n",
    "                    result[k] = v\n",
    "            else:\n",
    "                result[k] = v\n",
    "        #result.update(local_map)\n",
    "    logger.info(f\"Collisions (forms leading to different base word, and having same amount of citation): {collision_count}\")\n",
    "    logger.info(f\"Examples of collisions: {list(islice(collisions, 5))}\")\n",
    "    for k in result:\n",
    "        result[k] = result[k][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "048cd3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 2597\n",
      "INFO:root:Examples of collisions: ['адапраць', 'навяліцца', 'адчыняць', 'мурчэць', 'спіцца']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 139\n",
      "INFO:root:Examples of collisions: ['уладзімір', 'барыс', 'захар', 'маркаў', 'павел']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 1345\n",
      "INFO:root:Examples of collisions: ['гайка', 'дамка', 'ёта', 'важычаня', 'зажор']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 1155\n",
      "INFO:root:Examples of collisions: ['кум', 'лісце', 'кош', 'лёс', 'нома']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 954\n",
      "INFO:root:Examples of collisions: ['ростра', 'удава', 'тэхніка', 'трух', 'руно']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 150\n",
      "INFO:root:Examples of collisions: ['газелін', 'жабін', 'дэкартаў', 'дугласавы', 'кракадзілаў']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 84\n",
      "INFO:root:Examples of collisions: ['чыжовы', 'пупартавы', 'фраўнгоферавы', 'шчупакоў', 'сомавы']\n"
     ]
    }
   ],
   "source": [
    "#verbs\n",
    "v = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/V.xml')\n",
    "\n",
    "#proper nouns\n",
    "np = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/NP.xml')\n",
    "\n",
    "#nouns\n",
    "n1 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N1.xml')\n",
    "n2 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N2.xml')\n",
    "n3 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N3.xml')\n",
    "\n",
    "#adjectives\n",
    "adj1 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/A1.xml')\n",
    "adj2 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/A2.xml')\n",
    "\n",
    "WORD_MAP = {}\n",
    "WORD_MAP.update(v)\n",
    "WORD_MAP.update(np)\n",
    "WORD_MAP.update(n1)\n",
    "WORD_MAP.update(n2)\n",
    "WORD_MAP.update(n3)\n",
    "WORD_MAP.update(adj1)\n",
    "WORD_MAP.update(adj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11b12a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2282675\n"
     ]
    }
   ],
   "source": [
    "print(len(WORD_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c63417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рух\n",
      "беларусь\n"
     ]
    }
   ],
   "source": [
    "print(WORD_MAP['рухам'])\n",
    "print(WORD_MAP['беларусі'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca36540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_trailing_newline(iterable):\n",
    "    for i in iterable:\n",
    "        yield i.rstrip()\n",
    "\n",
    "CHARACTERS_MAP = {'ý': 'ў', 'i': 'і', 'ньн': 'нн', 'цьц': 'цц', 'сьц': 'сц', 'сьл':'сл'}\n",
    "def replace_characters(iterable):\n",
    "    for s in iterable:\n",
    "        for k, v in CHARACTERS_MAP.items():\n",
    "            s = s.replace(k, v)\n",
    "        yield s\n",
    "\n",
    "def split_sentences(iterable):\n",
    "    for i in iterable:\n",
    "        merged_dots = re.sub(\"[\\.]+\", \".\", i)\n",
    "        sentences = merged_dots.split('.')\n",
    "        for s in sentences:\n",
    "            yield s\n",
    "\n",
    "STOPWORDS = ['на', 'не', 'што', 'да', 'па', 'як', 'за', 'для', 'гэта', 'ад', 'але', 'калі', 'пра', 'у', 'яго', 'якія', 'ён', 'іх', 'мы', 'каб', 'толькі', 'аб', 'таксама', 'які', 'ці', 'быў', 'было', 'яны', 'так', 'вы', 'яе', 'будзе', 'пры', 'яшчэ', 'тым', 'таму', 'вельмі', 'былі', 'можна', 'яна', 'пасля', 'пад', 'можа', 'дзе', 'якая', 'тут', 'была', 'трэба', 'тое', 'таго', 'або', 'гэтым', 'бо', 'ўсё', 'хто', 'ня', 'нас', 'гэтага', 'быць', 'гэты', 'ёсць', 'праз', 'ўжо', 'са', 'нават', 'то', 'мяне', 'ім','ва', 'той', 'усе', 'без', 'чым', 'мне', 'мае', 'сябе', 'гэтай', 'там', 'усё', 'вось', 'ды', 'каля', 'якіх', 'ты', 'якой', 'ўсе', 'жа', 'ужо', 'паводле', 'будуць', 'аднак', 'могуць', 'сваю', 'ні', 'сваёй', 'яму', 'свае', 'гэтыя', 'проста', 'ўсіх', 'якім', 'падчас', 'тады', 'свой', 'вас', 'паміж', 'нам', 'раз', 'сваіх', 'нашай', 'менавіта', 'перад', 'вам', 'тых','зь','такім', 'свайго', 'над', 'зараз', 'амаль', 'чаму', 'ёй', 'чынам', 'напрыклад', 'якога', 'якое', 'сваім', 'можаце', 'га', 'хоць', 'бы', 'тыя', 'такія', 'потым', 'адным', 'такі', 'якую', 'сабе','сам','гэтых','мая','наш','зусім','чаго','наша','зноў','дык','такіх','нашага','адразу','каго','самі','ст','ну','нашы','нашым','самы','яно','гэтае','дзеля','куды','by','гг']\n",
    "def preprocess_sentences(iterable):\n",
    "    for i in iterable:\n",
    "        s = strip_multiple_whitespaces(strip_numeric(strip_short(strip_punctuation(i))))\n",
    "        s = s.lower()\n",
    "        s = re.sub(\"[«»“”„…—°′²]\", \"\", s)\n",
    "        s = remove_stopwords(s, stopwords=STOPWORDS)\n",
    "        s = ' '.join([WORD_MAP.get(w, w) for w in s.split()])\n",
    "        yield s\n",
    "\n",
    "def remove_short_lines(iterable):\n",
    "    for i in iterable:\n",
    "        if not i.isspace() and len(i) >= 20:\n",
    "            yield i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1044a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('be.txt', 'r') as original_file:\n",
    "    with open('sentences.txt', 'w') as sentences_file:\n",
    "        for s in remove_short_lines(preprocess_sentences(split_sentences(replace_characters(strip_trailing_newline(original_file))))):\n",
    "            sentences_file.write(s + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab9fc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "class Callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_list.append(loss)\n",
    "        print('Loss after epoch {}:{}'.format(self.epoch, loss))\n",
    "        model.running_training_loss = 0.0\n",
    "        self.epoch = self.epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e8337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.025>', 'datetime': '2023-04-23T10:21:24.381682', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(vector_size=100, window=3, min_count=10, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35054bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence('sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615cf92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #5000000, processed 44718951 words, keeping 810955 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000000, processed 89510301 words, keeping 1244638 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #15000000, processed 134174824 words, keeping 1580646 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000000, processed 178959997 words, keeping 1869907 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #25000000, processed 223611015 words, keeping 2135119 word types\n",
      "INFO:gensim.models.word2vec:collected 2151510 word types from a corpus of 226598275 raw words and 25339681 sentences\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 277148 unique words (12.88% of original 2151510, drops 1874362)', 'datetime': '2023-04-23T10:22:43.613278', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 222858920 word corpus (98.35% of original 226598275, drops 3739355)', 'datetime': '2023-04-23T10:22:43.613908', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 2151510 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 8 most-common words\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 219974521.6485438 word corpus (98.7%% of prior 222858920)', 'datetime': '2023-04-23T10:22:44.559747', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:estimated required memory for 277148 words and 100 dimensions: 360292400 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-23T10:22:46.416270', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences, progress_per=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "867dc13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 5 workers on 277148 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=3 shrink_windows=True', 'datetime': '2023-04-23T10:22:46.421779', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 0.59% examples, 1285232 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 0: training on 226598275 raw words (219974027 effective words) took 168.2s, 1307777 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:45621836.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 0.57% examples, 1239446 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1: training on 226598275 raw words (219973293 effective words) took 165.8s, 1326665 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1:44355904.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 0.56% examples, 1229852 words/s, in_qsize 8, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 2: training on 226598275 raw words (219970716 effective words) took 169.2s, 1299881 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 2:44249936.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 0.57% examples, 1257724 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3: training on 226598275 raw words (219972848 effective words) took 169.3s, 1299601 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 3:44104492.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 0.57% examples, 1257147 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4: training on 226598275 raw words (219972840 effective words) took 167.0s, 1317200 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 4:44107028.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 0.56% examples, 1220855 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 5: training on 226598275 raw words (219973851 effective words) took 167.2s, 1315802 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 5:44097436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 0.57% examples, 1247998 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6: training on 226598275 raw words (219974504 effective words) took 164.1s, 1340099 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 6:44270596.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 0.60% examples, 1290979 words/s, in_qsize 8, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 7: training on 226598275 raw words (219978018 effective words) took 166.0s, 1325076 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 7:44089604.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 0.59% examples, 1285402 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8: training on 226598275 raw words (219971424 effective words) took 168.8s, 1302828 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 8:44185456.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 0.58% examples, 1269394 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9: training on 226598275 raw words (219973625 effective words) took 168.2s, 1307447 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 9:44285424.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 0.58% examples, 1281159 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10: training on 226598275 raw words (219974854 effective words) took 166.2s, 1323511 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 10:44182396.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 0.58% examples, 1266807 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 11: training on 226598275 raw words (219975569 effective words) took 163.2s, 1347996 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 11:44126032.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 0.61% examples, 1331130 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 12: training on 226598275 raw words (219976024 effective words) took 162.5s, 1353878 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 12:44408908.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 0.61% examples, 1320703 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 13: training on 226598275 raw words (219975924 effective words) took 162.6s, 1353192 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 13:44199988.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 0.60% examples, 1303863 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 14: training on 226598275 raw words (219976300 effective words) took 163.0s, 1349379 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 14:44425624.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 0.57% examples, 1230728 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 15: training on 226598275 raw words (219974649 effective words) took 163.1s, 1348464 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 15:44209516.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 0.59% examples, 1288194 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 16: training on 226598275 raw words (219975068 effective words) took 162.1s, 1357146 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 16:44227556.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 0.57% examples, 1240406 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 17: training on 226598275 raw words (219974402 effective words) took 163.1s, 1348880 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 17:44041368.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 0.60% examples, 1295974 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 18: training on 226598275 raw words (219974102 effective words) took 163.2s, 1348227 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 18:44373620.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 0.60% examples, 1299461 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 19: training on 226598275 raw words (219977575 effective words) took 163.1s, 1348930 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 19:44456688.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 20 - PROGRESS: at 0.61% examples, 1315974 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 20: training on 226598275 raw words (219975905 effective words) took 162.7s, 1352306 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 20:44070200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 21 - PROGRESS: at 0.57% examples, 1225835 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 21: training on 226598275 raw words (219972785 effective words) took 162.9s, 1350639 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 21:43995008.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 22 - PROGRESS: at 0.59% examples, 1285921 words/s, in_qsize 8, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 22: training on 226598275 raw words (219975298 effective words) took 164.1s, 1340862 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 22:44134528.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 23 - PROGRESS: at 0.57% examples, 1260822 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 23: training on 226598275 raw words (219975682 effective words) took 166.9s, 1317976 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 23:44107632.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 24 - PROGRESS: at 0.56% examples, 1220400 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 24: training on 226598275 raw words (219976889 effective words) took 163.9s, 1342169 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 24:43802268.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 25 - PROGRESS: at 0.56% examples, 1228115 words/s, in_qsize 7, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 25: training on 226598275 raw words (219974616 effective words) took 164.3s, 1339165 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 25:44047244.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 26 - PROGRESS: at 0.59% examples, 1288834 words/s, in_qsize 9, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 26: training on 226598275 raw words (219973772 effective words) took 162.4s, 1354557 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 26:43904480.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 27 - PROGRESS: at 0.61% examples, 1332694 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 27: training on 226598275 raw words (219975927 effective words) took 161.9s, 1358850 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 27:43939264.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 28 - PROGRESS: at 0.61% examples, 1337086 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 28: training on 226598275 raw words (219974638 effective words) took 162.3s, 1355636 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 28:43987436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 29 - PROGRESS: at 0.56% examples, 1215030 words/s, in_qsize 10, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 29: training on 226598275 raw words (219976718 effective words) took 162.5s, 1353889 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 29:43859148.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 30 - PROGRESS: at 0.60% examples, 1297848 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 30: training on 226598275 raw words (219975108 effective words) took 167.9s, 1310297 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 30:43961468.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 31 - PROGRESS: at 0.52% examples, 1129432 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 31: training on 226598275 raw words (219974789 effective words) took 167.5s, 1312992 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 31:44073332.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 32 - PROGRESS: at 0.56% examples, 1221386 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 32: training on 226598275 raw words (219974057 effective words) took 163.0s, 1349360 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 32:43907992.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 33 - PROGRESS: at 0.60% examples, 1309765 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 33: training on 226598275 raw words (219975396 effective words) took 164.0s, 1341154 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 33:43725336.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 34 - PROGRESS: at 0.56% examples, 1219730 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 34: training on 226598275 raw words (219974172 effective words) took 163.8s, 1343150 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 34:43849884.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 35 - PROGRESS: at 0.55% examples, 1183189 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 35: training on 226598275 raw words (219974073 effective words) took 162.9s, 1350440 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 35:43924944.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 36 - PROGRESS: at 0.58% examples, 1233674 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 36: training on 226598275 raw words (219973451 effective words) took 163.9s, 1342488 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 36:43826232.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 37 - PROGRESS: at 0.58% examples, 1267448 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 37: training on 226598275 raw words (219975769 effective words) took 164.2s, 1339816 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 37:43496588.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 38 - PROGRESS: at 0.57% examples, 1248605 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 38: training on 226598275 raw words (219974046 effective words) took 163.9s, 1342048 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 38:43605268.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 39 - PROGRESS: at 0.62% examples, 1361229 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 39: training on 226598275 raw words (219974917 effective words) took 165.5s, 1328833 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 39:43641544.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 40 - PROGRESS: at 0.60% examples, 1307722 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 40: training on 226598275 raw words (219975880 effective words) took 162.4s, 1354273 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 40:43543980.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 41 - PROGRESS: at 0.59% examples, 1291145 words/s, in_qsize 9, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 41: training on 226598275 raw words (219972916 effective words) took 161.9s, 1358958 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 41:43537204.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 42 - PROGRESS: at 0.57% examples, 1259155 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 42: training on 226598275 raw words (219973201 effective words) took 162.9s, 1350317 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 42:43491140.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 43 - PROGRESS: at 0.61% examples, 1316216 words/s, in_qsize 7, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 43: training on 226598275 raw words (219973226 effective words) took 162.4s, 1354218 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 43:43373268.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 44 - PROGRESS: at 0.58% examples, 1277548 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 44: training on 226598275 raw words (219974399 effective words) took 161.8s, 1359165 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 44:43624628.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 45 - PROGRESS: at 0.62% examples, 1348850 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 45: training on 226598275 raw words (219973684 effective words) took 162.2s, 1356331 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 45:43330720.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 46 - PROGRESS: at 0.57% examples, 1247644 words/s, in_qsize 10, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 46: training on 226598275 raw words (219975907 effective words) took 162.5s, 1353521 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 46:43449924.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 47 - PROGRESS: at 0.60% examples, 1304291 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 47: training on 226598275 raw words (219973308 effective words) took 162.7s, 1351678 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 47:43234040.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 48 - PROGRESS: at 0.59% examples, 1289082 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 48: training on 226598275 raw words (219974737 effective words) took 162.7s, 1352363 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 48:43097712.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 49 - PROGRESS: at 0.57% examples, 1231720 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 49: training on 226598275 raw words (219976642 effective words) took 162.9s, 1350591 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 49:44565932.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 50 - PROGRESS: at 0.57% examples, 1246664 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 50: training on 226598275 raw words (219973589 effective words) took 166.2s, 1323798 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 50:43416728.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 51 - PROGRESS: at 0.61% examples, 1327862 words/s, in_qsize 10, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 51: training on 226598275 raw words (219976029 effective words) took 162.8s, 1351063 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 51:43234072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 52 - PROGRESS: at 0.57% examples, 1259336 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 52: training on 226598275 raw words (219973869 effective words) took 163.7s, 1343785 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 52:43260536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 53 - PROGRESS: at 0.60% examples, 1288929 words/s, in_qsize 9, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 53: training on 226598275 raw words (219974403 effective words) took 162.8s, 1350938 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 53:43074152.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 54 - PROGRESS: at 0.61% examples, 1286956 words/s, in_qsize 9, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 54: training on 226598275 raw words (219974071 effective words) took 162.6s, 1352967 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 54:43096868.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 55 - PROGRESS: at 0.57% examples, 1250614 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 55: training on 226598275 raw words (219974446 effective words) took 162.1s, 1357336 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 55:42714596.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 56 - PROGRESS: at 0.59% examples, 1294430 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 56: training on 226598275 raw words (219973803 effective words) took 162.7s, 1351755 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 56:43268708.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 57 - PROGRESS: at 0.59% examples, 1288494 words/s, in_qsize 8, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 57: training on 226598275 raw words (219973157 effective words) took 162.9s, 1350436 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 57:42984456.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 58 - PROGRESS: at 0.60% examples, 1312188 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 58: training on 226598275 raw words (219977179 effective words) took 163.8s, 1342758 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 58:43917916.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 59 - PROGRESS: at 0.57% examples, 1235182 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 59: training on 226598275 raw words (219975356 effective words) took 162.4s, 1354373 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 59:43035192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 60 - PROGRESS: at 0.61% examples, 1316582 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 60: training on 226598275 raw words (219975517 effective words) took 162.7s, 1352347 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 60:42818392.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 61 - PROGRESS: at 0.60% examples, 1302978 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 61: training on 226598275 raw words (219975453 effective words) took 162.6s, 1352693 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 61:42656488.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 62 - PROGRESS: at 0.60% examples, 1288687 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 62: training on 226598275 raw words (219975580 effective words) took 164.4s, 1337912 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 62:42411144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 63 - PROGRESS: at 0.59% examples, 1287263 words/s, in_qsize 8, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 63: training on 226598275 raw words (219976178 effective words) took 164.8s, 1335091 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 63:42707748.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 64 - PROGRESS: at 0.58% examples, 1264672 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 64: training on 226598275 raw words (219974815 effective words) took 165.3s, 1330678 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 64:42523348.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 65 - PROGRESS: at 0.61% examples, 1330019 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 65: training on 226598275 raw words (219976008 effective words) took 165.9s, 1325569 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 65:42491780.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 66 - PROGRESS: at 0.59% examples, 1285157 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 66: training on 226598275 raw words (219975676 effective words) took 162.6s, 1352884 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 66:42605616.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 67 - PROGRESS: at 0.58% examples, 1264806 words/s, in_qsize 10, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 67: training on 226598275 raw words (219974275 effective words) took 163.1s, 1348813 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 67:42294312.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 68 - PROGRESS: at 0.59% examples, 1284191 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 68: training on 226598275 raw words (219973402 effective words) took 162.9s, 1350429 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 68:42310540.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 69 - PROGRESS: at 0.61% examples, 1329519 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 69: training on 226598275 raw words (219975410 effective words) took 167.3s, 1315096 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 69:42306532.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 70 - PROGRESS: at 0.57% examples, 1232986 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 70: training on 226598275 raw words (219975846 effective words) took 165.2s, 1331236 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 70:42327836.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 71 - PROGRESS: at 0.59% examples, 1277081 words/s, in_qsize 10, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 71: training on 226598275 raw words (219973789 effective words) took 165.0s, 1333246 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 71:42028380.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 72 - PROGRESS: at 0.56% examples, 1230691 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 72: training on 226598275 raw words (219974319 effective words) took 163.3s, 1347387 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 72:43780020.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 73 - PROGRESS: at 0.58% examples, 1235741 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 73: training on 226598275 raw words (219973787 effective words) took 163.7s, 1343876 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 73:41960848.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 74 - PROGRESS: at 0.59% examples, 1291214 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 74: training on 226598275 raw words (219975906 effective words) took 162.7s, 1352344 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 74:41753348.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 75 - PROGRESS: at 0.59% examples, 1288191 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 75: training on 226598275 raw words (219974505 effective words) took 162.7s, 1351786 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 75:41644528.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 76 - PROGRESS: at 0.60% examples, 1289534 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 76: training on 226598275 raw words (219976754 effective words) took 161.9s, 1358510 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 76:42072300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 77 - PROGRESS: at 0.60% examples, 1303552 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 77: training on 226598275 raw words (219974839 effective words) took 162.3s, 1355546 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 77:41830796.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 78 - PROGRESS: at 0.59% examples, 1288603 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 78: training on 226598275 raw words (219974814 effective words) took 162.0s, 1357814 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 78:41535968.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 79 - PROGRESS: at 0.60% examples, 1313499 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 79: training on 226598275 raw words (219974106 effective words) took 163.5s, 1345263 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 79:41507712.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 80 - PROGRESS: at 0.62% examples, 1345613 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 80: training on 226598275 raw words (219975950 effective words) took 162.8s, 1351596 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 80:41336916.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 81 - PROGRESS: at 0.60% examples, 1297655 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 81: training on 226598275 raw words (219975359 effective words) took 164.6s, 1336307 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 81:41256888.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 82 - PROGRESS: at 0.61% examples, 1339988 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 82: training on 226598275 raw words (219976077 effective words) took 165.1s, 1332427 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 82:41069008.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 83 - PROGRESS: at 0.58% examples, 1251189 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 83: training on 226598275 raw words (219974498 effective words) took 165.2s, 1331947 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 83:40828812.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 84 - PROGRESS: at 0.61% examples, 1310733 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 84: training on 226598275 raw words (219973777 effective words) took 169.3s, 1299273 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 84:40791320.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 85 - PROGRESS: at 0.33% examples, 717258 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 85 - PROGRESS: at 97.37% examples, 1183709 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 85: training on 226598275 raw words (219975092 effective words) took 185.2s, 1187861 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 85:40758012.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 86 - PROGRESS: at 0.59% examples, 1290950 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 86 - PROGRESS: at 89.91% examples, 1093331 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 86: training on 226598275 raw words (219975540 effective words) took 197.3s, 1115172 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 86:40487952.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 87 - PROGRESS: at 0.60% examples, 1309750 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 87 - PROGRESS: at 96.41% examples, 1172059 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 87: training on 226598275 raw words (219976256 effective words) took 187.0s, 1176567 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 87:40521400.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 88 - PROGRESS: at 0.59% examples, 1279997 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 88: training on 226598275 raw words (219973682 effective words) took 165.4s, 1329723 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 88:40385292.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 89 - PROGRESS: at 0.57% examples, 1247837 words/s, in_qsize 6, out_qsize 4\n",
      "INFO:gensim.models.word2vec:EPOCH 89: training on 226598275 raw words (219975453 effective words) took 162.5s, 1353799 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 89:40164828.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 90 - PROGRESS: at 0.61% examples, 1324819 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 90: training on 226598275 raw words (219974285 effective words) took 160.8s, 1368082 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 90:41217672.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 91 - PROGRESS: at 0.60% examples, 1303267 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 91: training on 226598275 raw words (219975658 effective words) took 163.6s, 1344894 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 91:39945608.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 92 - PROGRESS: at 0.59% examples, 1288817 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 92: training on 226598275 raw words (219974707 effective words) took 164.6s, 1336217 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 92:39633816.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 93 - PROGRESS: at 0.58% examples, 1254160 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 93: training on 226598275 raw words (219973866 effective words) took 164.6s, 1336219 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 93:39335348.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 94 - PROGRESS: at 0.60% examples, 1310293 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 94: training on 226598275 raw words (219972398 effective words) took 162.7s, 1352168 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 94:39096012.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 95 - PROGRESS: at 0.58% examples, 1249518 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 95: training on 226598275 raw words (219975120 effective words) took 164.8s, 1334533 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 95:39050096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 96 - PROGRESS: at 0.56% examples, 1230837 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 96: training on 226598275 raw words (219974766 effective words) took 164.4s, 1337764 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 96:38497092.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 97 - PROGRESS: at 0.58% examples, 1257876 words/s, in_qsize 10, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 97: training on 226598275 raw words (219973377 effective words) took 164.6s, 1336298 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 97:38436708.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 98 - PROGRESS: at 0.58% examples, 1281189 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 98: training on 226598275 raw words (219973683 effective words) took 168.8s, 1303259 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 98:38193532.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 99 - PROGRESS: at 0.58% examples, 1280493 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 99: training on 226598275 raw words (219974942 effective words) took 168.1s, 1308280 effective words/s\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 22659827500 raw words (21997472888 effective words) took 16488.3s, 1334127 effective words/s', 'datetime': '2023-04-23T15:48:08.114033', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 99:37834140.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21997472888, 22659827500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, epochs=100, total_examples=model.corpus_count, total_words=model.corpus_total_words, compute_loss=True, report_delay=180, callbacks=[Callback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec534c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec-100-bel-cc100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "625cd5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кастаненка', 0.6006743907928467),\n",
       " ('клешчукевіч', 0.5838990211486816),\n",
       " ('беляжэнкі', 0.5773590803146362),\n",
       " ('крэпак', 0.5444377660751343),\n",
       " ('чарнаглаз', 0.5400937795639038),\n",
       " ('патон', 0.5291008353233337),\n",
       " ('звоскага', 0.5288887619972229),\n",
       " ('вальеха', 0.5172730684280396),\n",
       " ('святловым', 0.5152472853660583),\n",
       " ('бачкоўскі', 0.511944591999054),\n",
       " ('нікульшын', 0.5117442011833191),\n",
       " ('бокшы', 0.5115799903869629),\n",
       " ('грабеншчыкоў', 0.506933331489563),\n",
       " ('герстэн', 0.5058147311210632),\n",
       " ('заборава', 0.4989950656890869),\n",
       " ('эрына', 0.4967189133167267),\n",
       " ('рагуля', 0.4914279878139496),\n",
       " ('ласкорын', 0.4895833432674408),\n",
       " ('грабеншчыкова', 0.48926597833633423),\n",
       " ('парафянюк', 0.48552122712135315)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('кіт', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "465b441c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['год',\n",
       " 'беларускі',\n",
       " 'беларусь',\n",
       " 'чалавек',\n",
       " 'час',\n",
       " 'дзень',\n",
       " 'большыць',\n",
       " 'мова',\n",
       " 'новы',\n",
       " 'вялікі',\n",
       " 'краіна',\n",
       " 'жыццё',\n",
       " 'праца',\n",
       " 'горад',\n",
       " 'месца',\n",
       " 'справа',\n",
       " 'гісторыя',\n",
       " 'рэспубліка',\n",
       " 'слова',\n",
       " 'кожны',\n",
       " 'гульня',\n",
       " 'дзіцё',\n",
       " 'дзяржаўны',\n",
       " 'сайт',\n",
       " 'працаваць',\n",
       " 'нацыянальны',\n",
       " 'раён',\n",
       " 'пытанне',\n",
       " 'імя',\n",
       " 'казаць',\n",
       " 'галоўны',\n",
       " 'свет',\n",
       " 'культура',\n",
       " 'кніга',\n",
       " 'старонка',\n",
       " 'мець',\n",
       " 'раз',\n",
       " 'другі',\n",
       " 'атрымаць',\n",
       " 'розны',\n",
       " 'адзін',\n",
       " 'арганізацыя',\n",
       " 'школа',\n",
       " 'апошні',\n",
       " 'адбыцца',\n",
       " 'ведаць',\n",
       " 'дом',\n",
       " 'зрабіць',\n",
       " 'мінск',\n",
       " 'цэнтр',\n",
       " 'матэрыял',\n",
       " 'вынік',\n",
       " 'хацець',\n",
       " 'правіць',\n",
       " 'рабіць',\n",
       " 'праект',\n",
       " 'цяпер',\n",
       " 'беларус',\n",
       " 'права',\n",
       " 'адукацыя',\n",
       " 'вайна',\n",
       " 'частка',\n",
       " 'праграма',\n",
       " 'жыць',\n",
       " 'дзяржава',\n",
       " 'зямля',\n",
       " 'шмат',\n",
       " 'міжнародны',\n",
       " 'сёння',\n",
       " 'гад',\n",
       " 'работа',\n",
       " 'інфармацыя',\n",
       " 'развіццё',\n",
       " 'выбар',\n",
       " 'няма',\n",
       " 'лепшы',\n",
       " 'народны',\n",
       " 'яўляцца',\n",
       " 'наступны',\n",
       " 'палітычны',\n",
       " 'іншых',\n",
       " 'праблема',\n",
       " 'пачатак',\n",
       " 'вёска',\n",
       " 'народ',\n",
       " 'магчы',\n",
       " 'аляксандр',\n",
       " 'кіраўнік',\n",
       " 'знаходзіцца',\n",
       " 'мяжа',\n",
       " 'стол',\n",
       " 'літаратура',\n",
       " 'бацька',\n",
       " 'артыкул',\n",
       " 'дзейнасць',\n",
       " 'магчымасць',\n",
       " 'выпадак',\n",
       " 'ісці',\n",
       " 'пачаць',\n",
       " 'дапамога',\n",
       " 'бок',\n",
       " 'вобласць',\n",
       " 'асноўны',\n",
       " 'сказаць',\n",
       " 'сябар',\n",
       " 'выкарыстанне',\n",
       " 'аўтар',\n",
       " 'лукашэнка',\n",
       " 'добры',\n",
       " 'кампанія',\n",
       " 'прайсці',\n",
       " 'першае',\n",
       " 'колькасць',\n",
       " 'некалькі',\n",
       " 'суд',\n",
       " 'сучасны',\n",
       " 'мясцовы',\n",
       " 'сістэма',\n",
       " 'прадстаўнік',\n",
       " 'тэрыторыя',\n",
       " 'сярод',\n",
       " 'малады',\n",
       " 'любы',\n",
       " 'знайсці',\n",
       " 'прэзідэнт',\n",
       " 'музей',\n",
       " 'многі',\n",
       " 'свабода',\n",
       " 'жанчына',\n",
       " 'старшыня',\n",
       " 'два',\n",
       " 'іншыя',\n",
       " 'навука',\n",
       " 'бачыць',\n",
       " 'савет',\n",
       " 'спасылка',\n",
       " 'рука',\n",
       " 'лік',\n",
       " 'група',\n",
       " 'сказ',\n",
       " 'лічыць',\n",
       " 'крыніца',\n",
       " 'родны',\n",
       " 'некаторыя',\n",
       " 'мастацтва',\n",
       " 'сустрэча',\n",
       " 'конкурс',\n",
       " 'сіла',\n",
       " 'польскі',\n",
       " 'назва',\n",
       " 'грамадскі',\n",
       " 'супраць',\n",
       " 'тэма',\n",
       " 'першы',\n",
       " 'інтэрнэт',\n",
       " 'даваць',\n",
       " 'царква',\n",
       " 'дадзены',\n",
       " 'падзея',\n",
       " 'тысяча',\n",
       " 'мерапрыемства',\n",
       " 'твор',\n",
       " 'шлях',\n",
       " 'гістарычны',\n",
       " 'мэта',\n",
       " 'украіна',\n",
       " 'рашэнне',\n",
       " 'якасць',\n",
       " 'клас',\n",
       " 'менск',\n",
       " 'расія',\n",
       " 'савецкі',\n",
       " 'газета',\n",
       " 'бібліятэка',\n",
       " 'сувязь',\n",
       " 'рэч',\n",
       " 'польшча',\n",
       " 'радыё',\n",
       " 'стагоддзе',\n",
       " 'вядомы',\n",
       " 'палітык',\n",
       " 'агульны',\n",
       " 'студэнт',\n",
       " 'сакавік',\n",
       " 'пісаць',\n",
       " 'партыя',\n",
       " 'відэа',\n",
       " 'месяц',\n",
       " 'пісьменнік',\n",
       " 'сын',\n",
       " 'бог',\n",
       " 'міністр',\n",
       " 'рух',\n",
       " 'сацыяльны',\n",
       " 'жыхар',\n",
       " 'працэс',\n",
       " 'сродак',\n",
       " 'пакуль',\n",
       " 'акцыя',\n",
       " 'склад',\n",
       " 'заўсёды',\n",
       " 'стан',\n",
       " 'сітуацыя',\n",
       " 'церці',\n",
       " 'катэгорыя',\n",
       " 'вуліца',\n",
       " 'галіна',\n",
       " 'адзначыць',\n",
       " 'тыдзень',\n",
       " 'момант',\n",
       " 'канец',\n",
       " 'сярэдні',\n",
       " 'мінскі',\n",
       " 'форма',\n",
       " 'добра',\n",
       " 'міністэрства',\n",
       " 'даць',\n",
       " 'святы',\n",
       " 'кастрычнік',\n",
       " 'улада',\n",
       " 'адказ',\n",
       " 'павінны',\n",
       " 'свята',\n",
       " 'мінулы',\n",
       " 'прыйсці',\n",
       " 'эканамічны',\n",
       " 'уладзімір',\n",
       " 'гадзіна',\n",
       " 'тэкст',\n",
       " 'высокі',\n",
       " 'усё',\n",
       " 'выкарыстоўваць',\n",
       " 'саюз',\n",
       " 'закон',\n",
       " 'асоба',\n",
       " 'прыняць',\n",
       " 'рускі',\n",
       " 'думка',\n",
       " 'ліпень',\n",
       " 'гаварыць',\n",
       " 'верш',\n",
       " 'выданне',\n",
       " 'нашы',\n",
       " 'культурны',\n",
       " 'стары',\n",
       " 'лістапад',\n",
       " 'аднаго',\n",
       " 'верасень',\n",
       " 'грамадзянін',\n",
       " 'насельніцтва',\n",
       " 'зыходнік',\n",
       " 'маці',\n",
       " 'стаў',\n",
       " 'застацца',\n",
       " 'сусветны',\n",
       " 'паэт',\n",
       " 'курс',\n",
       " 'пайсці',\n",
       " 'працяг',\n",
       " 'даль',\n",
       " 'раней',\n",
       " 'дзіцячы',\n",
       " 'вядома',\n",
       " 'раённы',\n",
       " 'праўда',\n",
       " 'замежны',\n",
       " 'акрамя',\n",
       " 'стварэнне',\n",
       " 'мастацкі',\n",
       " 'адносіна',\n",
       " 'песня',\n",
       " 'дакумент',\n",
       " 'журналіст',\n",
       " 'вада',\n",
       " 'касцёл',\n",
       " 'атрымліваць',\n",
       " 'падтрымка',\n",
       " 'камітэт',\n",
       " 'расійскі',\n",
       " 'гарадскі',\n",
       " 'афіцыйны',\n",
       " 'зша',\n",
       " 'навіна',\n",
       " 'навуковы',\n",
       " 'варта',\n",
       " 'студзень',\n",
       " 'музыка',\n",
       " 'сяргей',\n",
       " 'нічога',\n",
       " 'зразумець',\n",
       " 'дзеянне',\n",
       " 'часопіс',\n",
       " 'існаваць',\n",
       " 'цікавы',\n",
       " 'чэрвень',\n",
       " 'выйсці',\n",
       " 'поўны',\n",
       " 'служба',\n",
       " 'чакаць',\n",
       " 'нарадзіцца',\n",
       " 'глядзець',\n",
       " 'правы',\n",
       " 'прычына',\n",
       " 'прапанаваць',\n",
       " 'быць',\n",
       " 'белы',\n",
       " 'меншыць',\n",
       " 'правіла',\n",
       " 'асабліва',\n",
       " 'удзел',\n",
       " 'моладзь',\n",
       " 'красавік',\n",
       " 'асобны',\n",
       " 'правядзенне',\n",
       " 'стварыць',\n",
       " 'файл',\n",
       " 'адбывацца',\n",
       " 'даследаванне',\n",
       " 'чат',\n",
       " 'інстытут',\n",
       " 'камісія',\n",
       " 'вучань',\n",
       " 'памяць',\n",
       " 'ідэя',\n",
       " 'адзіны',\n",
       " 'з’яўляецца',\n",
       " 'адна',\n",
       " 'будынак',\n",
       " 'гэтая',\n",
       " 'змена',\n",
       " 'еўропа',\n",
       " 'пункт',\n",
       " 'люты',\n",
       " 'падобны',\n",
       " 'прадпрыемства',\n",
       " 'пэўны',\n",
       " 'онлайн',\n",
       " 'жнівень',\n",
       " 'расейскі',\n",
       " 'паведаміць',\n",
       " 'ліст',\n",
       " 'заставацца',\n",
       " 'абарона',\n",
       " 'літоўскі',\n",
       " 'адной',\n",
       " 'рубель',\n",
       " 'навучанне',\n",
       " 'сапраўдны',\n",
       " 'установа',\n",
       " 'кандыдат',\n",
       " 'правесці',\n",
       " 'беларуска',\n",
       " 'веды',\n",
       " 'супрацоўнік',\n",
       " 'намеснік',\n",
       " 'годдзе',\n",
       " 'удзельнік',\n",
       " 'важны',\n",
       " 'дарога',\n",
       " 'выстава',\n",
       " 'займацца',\n",
       " 'былы',\n",
       " 'здароўе',\n",
       " 'магчыма',\n",
       " 'выгляд',\n",
       " 'каманда',\n",
       " 'тэрмін',\n",
       " 'рэгіён',\n",
       " 'абласны',\n",
       " 'ўсім',\n",
       " 'універсітэт',\n",
       " 'рэдагаваць',\n",
       " 'змагчы',\n",
       " 'вока',\n",
       " 'від',\n",
       " 'помнік',\n",
       " 'павінна',\n",
       " 'альбо',\n",
       " 'еўрапейскі',\n",
       " 'дэпутат',\n",
       " 'алесь',\n",
       " 'андрэй',\n",
       " 'тэатр',\n",
       " 'снежань',\n",
       " 'грош',\n",
       " 'перыяд',\n",
       " 'гаспадарка',\n",
       " 'сваё',\n",
       " 'фота',\n",
       " 'найбольш',\n",
       " 'грамадства',\n",
       " 'масква',\n",
       " 'кошт',\n",
       " 'творчасць',\n",
       " 'заходні',\n",
       " 'гэтую',\n",
       " 'неабходны',\n",
       " 'разумець',\n",
       " 'фестываль',\n",
       " 'мастак',\n",
       " 'план',\n",
       " 'большасць',\n",
       " 'плошча',\n",
       " 'творчы',\n",
       " 'воля',\n",
       " 'сэрца',\n",
       " 'гісторык',\n",
       " 'малы',\n",
       " 'цалок',\n",
       " 'дапамагчы',\n",
       " 'працоўны',\n",
       " 'чытаць',\n",
       " 'дадатковы',\n",
       " 'дырэктар',\n",
       " 'любіць',\n",
       " 'вырашыць',\n",
       " 'літаратурны',\n",
       " 'перамога',\n",
       " 'нараджэнне',\n",
       " 'часта',\n",
       " 'актыўны',\n",
       " 'маг',\n",
       " 'захад',\n",
       " 'орган',\n",
       " 'фільм',\n",
       " 'сапраўды',\n",
       " 'адкрыты',\n",
       " 'усіх',\n",
       " 'доўгі',\n",
       " 'такой',\n",
       " 'бясплатны',\n",
       " 'дзякаваць',\n",
       " 'аснова',\n",
       " 'такое',\n",
       " 'цябе',\n",
       " 'падрыхтоўка',\n",
       " 'пачацца',\n",
       " 'павінен',\n",
       " 'ўдзел',\n",
       " 'невялікі',\n",
       " 'аддзел',\n",
       " 'актывіст',\n",
       " 'запрашаць',\n",
       " 'мужчына',\n",
       " 'мой',\n",
       " 'шэраг',\n",
       " 'спіс',\n",
       " 'кіраўніцтва',\n",
       " 'ахова',\n",
       " 'ніколі',\n",
       " 'нешта',\n",
       " 'папярэдні',\n",
       " 'заявіць',\n",
       " 'факт',\n",
       " 'рэжым',\n",
       " 'дазваляць',\n",
       " 'парадак',\n",
       " 'увага',\n",
       " 'сталь',\n",
       " 'прыклад',\n",
       " 'традыцыя',\n",
       " 'дзейнічаць',\n",
       " 'паслуга',\n",
       " 'жонка',\n",
       " 'здавацца',\n",
       " 'герой',\n",
       " 'госць',\n",
       " 'cookіes',\n",
       " 'мікалай',\n",
       " 'вярнуцца',\n",
       " 'цэлы',\n",
       " 'вясна',\n",
       " 'рэспубліканскі',\n",
       " 'настаўнік',\n",
       " 'пакінуць',\n",
       " 'роля',\n",
       " 'першай',\n",
       " 'гуляць',\n",
       " 'стаць',\n",
       " 'электронны',\n",
       " 'эканоміка',\n",
       " 'будаўніцтва',\n",
       " 'дзяўчына',\n",
       " 'спецыяліст',\n",
       " 'значны',\n",
       " 'хутка',\n",
       " 'цэнтральны',\n",
       " 'май',\n",
       " 'неба',\n",
       " 'пераклад',\n",
       " 'душ',\n",
       " 'неабходна',\n",
       " 'ніхто',\n",
       " 'праваслаўны',\n",
       " 'шукаць',\n",
       " 'божы',\n",
       " 'вышэйшы',\n",
       " 'паказаць',\n",
       " 'прэмія',\n",
       " 'канферэнцыя',\n",
       " 'вытворчасць',\n",
       " 'задача',\n",
       " 'чырвоны',\n",
       " 'войска',\n",
       " 'масавы',\n",
       " 'сфера',\n",
       " 'клуб',\n",
       " 'ступень',\n",
       " 'спадчына',\n",
       " 'даведацца',\n",
       " 'самых',\n",
       " 'асобы',\n",
       " 'прысвечаны',\n",
       " 'сабой',\n",
       " 'складаць',\n",
       " 'прэс',\n",
       " 'брат',\n",
       " 'палова',\n",
       " 'канцэрт',\n",
       " 'літва',\n",
       " 'прафесійны',\n",
       " 'нямецкі',\n",
       " 'ўлады',\n",
       " 'рэгістрацыя',\n",
       " 'нумар',\n",
       " 'колька',\n",
       " 'незалежнасць',\n",
       " 'музычны',\n",
       " 'смерць',\n",
       " 'ваенны',\n",
       " 'варыянт',\n",
       " 'ласка',\n",
       " 'праводзіць',\n",
       " 'каталіцкі',\n",
       " 'князь',\n",
       " 'перайсці',\n",
       " 'выходзіць',\n",
       " 'кіраванне',\n",
       " 'рынак',\n",
       " 'вікіпедыя',\n",
       " 'ноч',\n",
       " 'край',\n",
       " 'акадэмія',\n",
       " 'пара',\n",
       " 'адно',\n",
       " 'значэнне',\n",
       " 'значыць',\n",
       " 'віцебскі',\n",
       " 'ўмовы',\n",
       " 'сваімі',\n",
       " 'выкананне',\n",
       " 'майстар',\n",
       " 'адрас',\n",
       " 'паветра',\n",
       " 'сход',\n",
       " 'лес',\n",
       " 'член',\n",
       " 'княства',\n",
       " 'любоў',\n",
       " 'звязаны',\n",
       " 'умова',\n",
       " 'стаяць',\n",
       " 'такай',\n",
       " 'тэхнічны',\n",
       " 'рацыя',\n",
       " 'памерці',\n",
       " 'асабісты',\n",
       " 'блізкі',\n",
       " 'чарга',\n",
       " 'тэмпература',\n",
       " 'патрабаваць',\n",
       " 'прымаць',\n",
       " 'тэхналогія',\n",
       " 'калектыў',\n",
       " 'парушэнне',\n",
       " 'браць',\n",
       " 'атрыманне',\n",
       " 'голас',\n",
       " 'моцны',\n",
       " 'дарэчы',\n",
       " 'грамадзянскі',\n",
       " 'двух',\n",
       " 'лепшыць',\n",
       " 'супрацоўніцтва',\n",
       " 'навучальны',\n",
       " 'пасад',\n",
       " 'вера',\n",
       " 'выбарчы',\n",
       " 'размова',\n",
       " 'міліцыя',\n",
       " 'гурт',\n",
       " 'сетка',\n",
       " 'адмовіцца',\n",
       " 'рэсурс',\n",
       " 'супольнасць',\n",
       " 'сельскі',\n",
       " 'запіс',\n",
       " 'сталіца',\n",
       " 'c',\n",
       " 'дума',\n",
       " 'жывы',\n",
       " 'база',\n",
       " 'крымінальны',\n",
       " 'работнік',\n",
       " 'праваабаронца',\n",
       " 'большы',\n",
       " 'інфармацыйны',\n",
       " 'бяспека',\n",
       " 'працягваць',\n",
       " 'вучыцца',\n",
       " 'барацьба',\n",
       " 'дапамагаць',\n",
       " 'небудзь',\n",
       " 'збор',\n",
       " 'галава',\n",
       " 'хвіліна',\n",
       " 'элемент',\n",
       " 'рака',\n",
       " 'іван',\n",
       " 'таварыства',\n",
       " 'хата',\n",
       " 'прырода',\n",
       " 'патрэбны',\n",
       " 'прадукт',\n",
       " 'маленькі',\n",
       " 'адчуваць',\n",
       " 'незалежны',\n",
       " 'выклікаць',\n",
       " 'публікацыя',\n",
       " 'дзеяч',\n",
       " 'насіць',\n",
       " 'паўночны',\n",
       " 'прыгожы',\n",
       " 'спрабаваць',\n",
       " 'машына',\n",
       " 'расеі',\n",
       " 'памер',\n",
       " 'кватэра',\n",
       " 'сэнс',\n",
       " 'узровень',\n",
       " 'пошук',\n",
       " 'чорны',\n",
       " 'нельга',\n",
       " 'адпаведны',\n",
       " 'хуткасць',\n",
       " 'банк',\n",
       " 'гадовы',\n",
       " 'надвор',\n",
       " 'называць',\n",
       " 'шырокі',\n",
       " 'віктар',\n",
       " 'бізнес',\n",
       " 'думаць',\n",
       " 'лёс',\n",
       " 'прапанова',\n",
       " 'прыехаць',\n",
       " 'чытач',\n",
       " 'поспех',\n",
       " 'такога',\n",
       " 'бясплатна',\n",
       " 'айчынны',\n",
       " 'мусіць',\n",
       " 'род',\n",
       " 'зварот',\n",
       " 'дзве',\n",
       " 'начальнік',\n",
       " 'даволі',\n",
       " 'шматлікі',\n",
       " 'належаць',\n",
       " 'замак',\n",
       " 'гатовы',\n",
       " 'прадукцыя',\n",
       " 'характар',\n",
       " 'віцебск',\n",
       " 'выдатны',\n",
       " 'просты',\n",
       " 'гонар',\n",
       " 'адкрыццё',\n",
       " 'сезон',\n",
       " 'будучы',\n",
       " 'чарговы',\n",
       " 'заява',\n",
       " 'спартыўны',\n",
       " 'пакаранне',\n",
       " 'ініцыятыва',\n",
       " 'магілёўскі',\n",
       " 'адпачынак',\n",
       " 'даступны',\n",
       " 'змяніць',\n",
       " 'знак',\n",
       " 'створаны',\n",
       " 'ўмовах',\n",
       " 'спецыяльны',\n",
       " 'спачатку',\n",
       " 'дрэва',\n",
       " 'ссср',\n",
       " 'дачыненне',\n",
       " 'звычайны',\n",
       " 'вечар',\n",
       " 'самым',\n",
       " 'патрабаванне',\n",
       " 'парк',\n",
       " 'каштоўнасць',\n",
       " 'пачынаць',\n",
       " 'распавесці',\n",
       " 'хацецца',\n",
       " 'адказнасць',\n",
       " 'рэдактар',\n",
       " 'ўсяго',\n",
       " 'сцяг',\n",
       " 'асаблівы',\n",
       " 'праводзіцца',\n",
       " 'азначаць',\n",
       " 'армія',\n",
       " 'погляд',\n",
       " 'хадзіць',\n",
       " 'папулярны',\n",
       " 'кропка',\n",
       " 'факультэт',\n",
       " 'спорт',\n",
       " 'прахадзіць',\n",
       " 'дэмакратычны',\n",
       " 'абавязковы',\n",
       " 'нягледзячы',\n",
       " 'стыль',\n",
       " 'крок',\n",
       " 'сям',\n",
       " 'выконваць',\n",
       " 'тэлефон',\n",
       " 'штат',\n",
       " 'сённяшні',\n",
       " 'дазволіць',\n",
       " 'раман',\n",
       " 'занятак',\n",
       " 'рамка',\n",
       " 'прасіць',\n",
       " 'выкарыстоўвацца',\n",
       " 'станавіцца',\n",
       " 'сёлета',\n",
       " 'крама',\n",
       " 'этап',\n",
       " 'комплекс',\n",
       " 'гродзенскі',\n",
       " 'падстава',\n",
       " 'адміністрацыйны',\n",
       " 'браўзер',\n",
       " 'прадмет',\n",
       " 'трапіць',\n",
       " 'побач',\n",
       " 'карт',\n",
       " 'імкнуцца',\n",
       " 'поле',\n",
       " 'вопыт',\n",
       " 'васіль',\n",
       " 'паглядзець',\n",
       " 'адзначаць',\n",
       " 'меркаванне',\n",
       " 'ваш',\n",
       " 'лінія',\n",
       " 'мільён',\n",
       " 'карыстацца',\n",
       " 'трох',\n",
       " 'мера',\n",
       " 'цяжка',\n",
       " 'хаця',\n",
       " 'жывёла',\n",
       " 'фонд',\n",
       " 'дадаць',\n",
       " 'прыходзіць',\n",
       " 'марыя',\n",
       " 'зала',\n",
       " 'колер',\n",
       " 'таб',\n",
       " 'паказваць',\n",
       " 'купал',\n",
       " 'лета',\n",
       " 'дзяўчынка',\n",
       " 'размаўляць',\n",
       " 'завод',\n",
       " 'цяжкі',\n",
       " 'духоўны',\n",
       " 'хутчэй',\n",
       " 'прыватнасць',\n",
       " 'смі',\n",
       " 'спосаб',\n",
       " 'першыя',\n",
       " 'асаблівасць',\n",
       " 'сядзець',\n",
       " 'ствараць',\n",
       " 'весці',\n",
       " 'прыватны',\n",
       " 'прывесці',\n",
       " 'прынцып',\n",
       " 'сям’і',\n",
       " 'старажытны',\n",
       " 'самыя',\n",
       " 'цяперашні',\n",
       " 'намі',\n",
       " 'зборнік',\n",
       " 'рады',\n",
       " 'пазней',\n",
       " 'хлопец',\n",
       " 'птушка',\n",
       " 'заканадаўства',\n",
       " 'інш',\n",
       " 'дачка',\n",
       " 'дух',\n",
       " 'цела',\n",
       " 'узяць',\n",
       " 'сцяна',\n",
       " 'традыцыйны',\n",
       " 'затым',\n",
       " 'арганізатар',\n",
       " 'выступаць',\n",
       " 'значна',\n",
       " 'магчымы',\n",
       " 'звычайна',\n",
       " 'інтарэс',\n",
       " 'скончыць',\n",
       " 'хрысціянскі',\n",
       " 'наведаць',\n",
       " 'першая',\n",
       " 'набыць',\n",
       " 'пяць',\n",
       " 'рэдакцыя',\n",
       " 'структура',\n",
       " 'абавязкова',\n",
       " 'надзея',\n",
       " 'паведамляць',\n",
       " 'будучыня',\n",
       " 'спампаваць',\n",
       " 'хрыстос',\n",
       " 'кароткі',\n",
       " 'падтрымліваць',\n",
       " 'усходні',\n",
       " 'нагода',\n",
       " 'чатыры',\n",
       " 'буйны',\n",
       " 'даўно',\n",
       " 'радзіма',\n",
       " 'самае',\n",
       " 'форум',\n",
       " 'рост',\n",
       " 'ігар',\n",
       " 'хатні',\n",
       " 'райвыканкам',\n",
       " 'адміністрацыя',\n",
       " 'палац',\n",
       " 'пакаленне',\n",
       " 'патрэба',\n",
       " 'спадзявацца',\n",
       " 'скласці',\n",
       " '№',\n",
       " 'выступіць',\n",
       " 'пазіцыя',\n",
       " 'кантакт',\n",
       " 'пакой',\n",
       " 'міхаіл',\n",
       " 'раніца',\n",
       " 'лічыцца',\n",
       " 'паставіць',\n",
       " 'бываць',\n",
       " 'звярнуцца',\n",
       " 'гэтак',\n",
       " 'адпаведнасць',\n",
       " 'іншым',\n",
       " 'тып',\n",
       " 'максім',\n",
       " 'памяшканне',\n",
       " 'атрымацца',\n",
       " 'выраб',\n",
       " 'жаданне',\n",
       " 'меркаваць',\n",
       " 'маскоўскі',\n",
       " 'бсср',\n",
       " 'чалавечы',\n",
       " 'складацца',\n",
       " 'складаны',\n",
       " 'першую',\n",
       " 'храм',\n",
       " 'пляцоўка',\n",
       " 'займаць',\n",
       " 'явіцца',\n",
       " 'пройда',\n",
       " 'пастанова',\n",
       " 'кантроль',\n",
       " 'паўднёвы',\n",
       " 'сама',\n",
       " 'ехаць',\n",
       " 'прэзентацыя',\n",
       " 'паведамленне',\n",
       " 'загінуць',\n",
       " 'далейшы',\n",
       " 'размешчаны',\n",
       " 'муж',\n",
       " 'павал',\n",
       " 'астатні',\n",
       " 'вэб',\n",
       " 'версія',\n",
       " 'нага',\n",
       " 'ахвяра',\n",
       " 'травень',\n",
       " 'аўтамабіль',\n",
       " 'маць',\n",
       " 'пераможца',\n",
       " 'праверка',\n",
       " 'германій',\n",
       " 'лёгкі',\n",
       " 'ўвесь',\n",
       " 'важна',\n",
       " 'забеспячэнне',\n",
       " 'навукова',\n",
       " 'рэалізацыя',\n",
       " 'жаночы',\n",
       " 'рабочы',\n",
       " 'згодна',\n",
       " 'чуць',\n",
       " 'прастор',\n",
       " 'цікава',\n",
       " 'ўсёй',\n",
       " 'партал',\n",
       " 'колас',\n",
       " 'цана',\n",
       " 'жаль',\n",
       " 'пан',\n",
       " 'сад',\n",
       " 'жадаць',\n",
       " 'юрыдычны',\n",
       " 'прамы',\n",
       " 'вакол',\n",
       " 'тавар',\n",
       " 'тэг',\n",
       " 'рэальны',\n",
       " 'ставіцца',\n",
       " 'асяроддзе',\n",
       " 'прыём',\n",
       " 'подпіс',\n",
       " 'альбом',\n",
       " 'паколькі',\n",
       " 'служыць',\n",
       " 'зона',\n",
       " 'збірацца',\n",
       " 'свабодны',\n",
       " 'ален',\n",
       " 'баяцца',\n",
       " 'чыноўнік',\n",
       " 'сцэна',\n",
       " 'іншымі',\n",
       " 'іншага',\n",
       " 'кветка',\n",
       " 'станцыя',\n",
       " 'гродна',\n",
       " 'карыстальнік',\n",
       " 'вайсковы',\n",
       " 'становішча',\n",
       " 'сячы',\n",
       " 'звестка',\n",
       " 'фронт',\n",
       " 'менскі',\n",
       " 'аддзяленне',\n",
       " 'навуковец',\n",
       " 'педагог',\n",
       " 'заўважыць',\n",
       " 'паэзія',\n",
       " 'распрацоўка',\n",
       " 'твар',\n",
       " 'дата',\n",
       " 'дарослы',\n",
       " 'вольны',\n",
       " 'францый',\n",
       " 'фінансавы',\n",
       " 'напісаць',\n",
       " 'педагагічны',\n",
       " 'бнр',\n",
       " 'выглядаць',\n",
       " 'раса',\n",
       " 'падкрэсліць',\n",
       " 'анатоль',\n",
       " 'трымаць',\n",
       " 'магілёў',\n",
       " 'ер',\n",
       " 'найлепшы',\n",
       " 'навучэнец',\n",
       " 'адказваць',\n",
       " 'нагадаць',\n",
       " 'брэсцкі',\n",
       " 'тэхнік',\n",
       " 'змяненне',\n",
       " 'бак',\n",
       " 'аляксей',\n",
       " 'гэту',\n",
       " 'прававы',\n",
       " 'крыж',\n",
       " 'назваць',\n",
       " 'адзенне',\n",
       " 'крыха',\n",
       " 'сукенка',\n",
       " 'вобраз',\n",
       " 'школьны',\n",
       " 'ўвагу',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.get_vecattr(\"прыдумляць\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ea11f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45621836.0,\n",
       " 44355904.0,\n",
       " 44249936.0,\n",
       " 44104492.0,\n",
       " 44107028.0,\n",
       " 44097436.0,\n",
       " 44270596.0,\n",
       " 44089604.0,\n",
       " 44185456.0,\n",
       " 44285424.0,\n",
       " 44182396.0,\n",
       " 44126032.0,\n",
       " 44408908.0,\n",
       " 44199988.0,\n",
       " 44425624.0,\n",
       " 44209516.0,\n",
       " 44227556.0,\n",
       " 44041368.0,\n",
       " 44373620.0,\n",
       " 44456688.0,\n",
       " 44070200.0,\n",
       " 43995008.0,\n",
       " 44134528.0,\n",
       " 44107632.0,\n",
       " 43802268.0,\n",
       " 44047244.0,\n",
       " 43904480.0,\n",
       " 43939264.0,\n",
       " 43987436.0,\n",
       " 43859148.0,\n",
       " 43961468.0,\n",
       " 44073332.0,\n",
       " 43907992.0,\n",
       " 43725336.0,\n",
       " 43849884.0,\n",
       " 43924944.0,\n",
       " 43826232.0,\n",
       " 43496588.0,\n",
       " 43605268.0,\n",
       " 43641544.0,\n",
       " 43543980.0,\n",
       " 43537204.0,\n",
       " 43491140.0,\n",
       " 43373268.0,\n",
       " 43624628.0,\n",
       " 43330720.0,\n",
       " 43449924.0,\n",
       " 43234040.0,\n",
       " 43097712.0,\n",
       " 44565932.0,\n",
       " 43416728.0,\n",
       " 43234072.0,\n",
       " 43260536.0,\n",
       " 43074152.0,\n",
       " 43096868.0,\n",
       " 42714596.0,\n",
       " 43268708.0,\n",
       " 42984456.0,\n",
       " 43917916.0,\n",
       " 43035192.0,\n",
       " 42818392.0,\n",
       " 42656488.0,\n",
       " 42411144.0,\n",
       " 42707748.0,\n",
       " 42523348.0,\n",
       " 42491780.0,\n",
       " 42605616.0,\n",
       " 42294312.0,\n",
       " 42310540.0,\n",
       " 42306532.0,\n",
       " 42327836.0,\n",
       " 42028380.0,\n",
       " 43780020.0,\n",
       " 41960848.0,\n",
       " 41753348.0,\n",
       " 41644528.0,\n",
       " 42072300.0,\n",
       " 41830796.0,\n",
       " 41535968.0,\n",
       " 41507712.0,\n",
       " 41336916.0,\n",
       " 41256888.0,\n",
       " 41069008.0,\n",
       " 40828812.0,\n",
       " 40791320.0,\n",
       " 40758012.0,\n",
       " 40487952.0,\n",
       " 40521400.0,\n",
       " 40385292.0,\n",
       " 40164828.0,\n",
       " 41217672.0,\n",
       " 39945608.0,\n",
       " 39633816.0,\n",
       " 39335348.0,\n",
       " 39096012.0,\n",
       " 39050096.0,\n",
       " 38497092.0,\n",
       " 38436708.0,\n",
       " 38193532.0,\n",
       " 37834140.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "289d5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сабака'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_MAP['сабака']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36663efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
