{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a506a6",
   "metadata": {},
   "source": [
    "Corpus (be.txt) taken from CC100 dataset: https://metatext.io/datasets/cc100-belarusian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de7b8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_short, strip_numeric, strip_multiple_whitespaces, remove_stopwords\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dc6904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logging initialized\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, force = True)\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Logging initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49326e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "from itertools import islice\n",
    "\n",
    "def calculate_mapping_from_forms_to_base(filepath):\n",
    "    xml_doc = xml.dom.minidom.parse(filepath)\n",
    "    words = xml_doc.getElementsByTagName('Variant')\n",
    "    result = {}\n",
    "    collision_count = 0\n",
    "    collisions = set()\n",
    "    for word in words:\n",
    "        base = word.getAttribute('lemma').replace(\"+\", \"\")\n",
    "        forms_objs = word.getElementsByTagName('Form')\n",
    "        local_map = {}\n",
    "        citation_count = max([forms_obj.getAttribute('slouniki').count(',') for forms_obj in forms_objs]) + 1\n",
    "        for forms_obj in forms_objs:\n",
    "            if (len(forms_obj.childNodes) == 0):\n",
    "                logger.info(f\"Empty for {base}\")\n",
    "            else:\n",
    "                form = forms_obj.childNodes[0].data.replace(\"+\", \"\")\n",
    "                #if citation_count > 3:\n",
    "                local_map[form] = (base, citation_count)\n",
    "        for k, v in local_map.items():\n",
    "            if k in result:\n",
    "                if result[k][1] == v[1] and result[k][0] != v[0]:\n",
    "                    collision_count += 1\n",
    "                    collisions.add(v[0])\n",
    "                    collisions.add(result[k][0])\n",
    "                elif result[k][1] < v[1]:\n",
    "                    result[k] = v\n",
    "            else:\n",
    "                result[k] = v\n",
    "        #result.update(local_map)\n",
    "    logger.info(f\"Collisions (forms leading to different base word, and having same amount of citation): {collision_count}\")\n",
    "    logger.info(f\"Examples of collisions: {list(islice(collisions, 5))}\")\n",
    "    for k in result:\n",
    "        result[k] = result[k][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "048cd3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Empty for бібікі\n",
      "INFO:root:Empty for бібікі\n",
      "INFO:root:Empty for бібікі\n",
      "INFO:root:Empty for бібікі\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 1345\n",
      "INFO:root:Examples of collisions: ['імерэцінка', 'жаўталіст', 'гераін', 'века', 'абісінец']\n",
      "INFO:root:Empty for лапта\n",
      "INFO:root:Empty for мальба\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 1155\n",
      "INFO:root:Examples of collisions: ['мальдыўка', 'неспадзеў', 'корм', 'конь', 'падыспытная']\n",
      "INFO:root:Empty for тамада\n",
      "INFO:root:Empty for тамада\n",
      "INFO:root:Empty for фата\n",
      "INFO:root:Empty for чака\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 954\n",
      "INFO:root:Examples of collisions: ['тальк', 'цэфалаподы', 'развалы', 'сума', 'страйкам']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 142\n",
      "INFO:root:Examples of collisions: ['вітавы', 'крэчатавы', 'дугласавы', 'волатавы', 'войтавы']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 84\n",
      "INFO:root:Examples of collisions: ['чыжовы', 'пупартавы', 'чэпікавы', 'фраўнгоферавы', 'сомаў']\n"
     ]
    }
   ],
   "source": [
    "n1 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N1.xml')\n",
    "n2 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N2.xml')\n",
    "n3 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N3.xml')\n",
    "adj1 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/A1.xml')\n",
    "adj2 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/A2.xml')\n",
    "\n",
    "WORD_MAP = {}\n",
    "WORD_MAP.update(n1)\n",
    "WORD_MAP.update(n2)\n",
    "WORD_MAP.update(n3)\n",
    "WORD_MAP.update(adj1)\n",
    "WORD_MAP.update(adj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a11b12a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567761\n"
     ]
    }
   ],
   "source": [
    "print(len(WORD_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48c63417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рух'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_MAP['рухам']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca36540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_trailing_newline(iterable):\n",
    "    for i in iterable:\n",
    "        yield i.rstrip()\n",
    "\n",
    "CHARACTERS_MAP = {'ý': 'ў', 'i': 'і', 'ньн': 'нн', 'цьц': 'цц', 'сьц': 'сц', 'сьл':'сл'}\n",
    "def replace_characters(iterable):\n",
    "    for s in iterable:\n",
    "        for k, v in CHARACTERS_MAP.items():\n",
    "            s = s.replace(k, v)\n",
    "        yield s\n",
    "\n",
    "def split_sentences(iterable):\n",
    "    for i in iterable:\n",
    "        merged_dots = re.sub(\"[\\.]+\", \".\", i)\n",
    "        sentences = merged_dots.split('.')\n",
    "        for s in sentences:\n",
    "            yield s\n",
    "\n",
    "STOPWORDS = ['на', 'не', 'што', 'да', 'па', 'як', 'за', 'для', 'гэта', 'ад', 'але', 'калі', 'пра', 'у', 'яго', 'якія', 'ён', 'іх', 'мы', 'каб', 'толькі', 'аб', 'таксама', 'які', 'ці', 'быў', 'было', 'яны', 'так', 'вы', 'яе', 'будзе', 'пры', 'яшчэ', 'тым', 'таму', 'вельмі', 'былі', 'можна', 'яна', 'пасля', 'пад', 'можа', 'дзе', 'якая', 'тут', 'была', 'трэба', 'тое', 'таго', 'або', 'гэтым', 'бо', 'ўсё', 'хто', 'ня', 'нас', 'гэтага', 'быць', 'гэты', 'ёсць', 'праз', 'ўжо', 'са', 'нават', 'то', 'мяне', 'ім','ва', 'той', 'усе', 'без', 'чым', 'мне', 'мае', 'сябе', 'гэтай', 'там', 'усё', 'вось', 'ды', 'каля', 'якіх', 'ты', 'якой', 'ўсе', 'жа', 'ужо', 'паводле', 'будуць', 'аднак', 'могуць', 'сваю', 'ні', 'сваёй', 'яму', 'свае', 'гэтыя', 'проста', 'ўсіх', 'якім', 'падчас', 'тады', 'свой', 'вас', 'паміж', 'нам', 'раз', 'сваіх', 'нашай', 'менавіта', 'перад', 'вам', 'тых','зь','такім', 'свайго', 'над', 'зараз', 'амаль', 'чаму', 'ёй', 'чынам', 'напрыклад', 'якога', 'якое', 'сваім', 'можаце', 'га', 'хоць', 'бы', 'тыя', 'такія', 'потым', 'адным', 'такі', 'якую', 'сабе','сам','гэтых','мая','наш','зусім','чаго','наша','зноў','дык','такіх','нашага','адразу','каго','самі','ст','ну','нашы','нашым','самы','яно','гэтае','дзеля','куды','by','гг']\n",
    "def preprocess_sentences(iterable):\n",
    "    for i in iterable:\n",
    "        s = strip_multiple_whitespaces(strip_numeric(strip_short(strip_punctuation(i))))\n",
    "        s = s.lower()\n",
    "        s = re.sub(\"[«»“”„…—°′²]\", \"\", s)\n",
    "        s = remove_stopwords(s, stopwords=STOPWORDS)\n",
    "        s = ' '.join([WORD_MAP.get(w, w) for w in s.split()])\n",
    "        yield s\n",
    "\n",
    "def remove_short_lines(iterable):\n",
    "    for i in iterable:\n",
    "        if not i.isspace() and len(i) >= 20:\n",
    "            yield i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1044a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('be.txt', 'r') as original_file:\n",
    "    with open('sentences.txt', 'w') as sentences_file:\n",
    "        for s in remove_short_lines(preprocess_sentences(split_sentences(replace_characters(strip_trailing_newline(original_file))))):\n",
    "            sentences_file.write(s + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab9fc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "class Callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_list.append(loss)\n",
    "        print('Loss after epoch {}:{}'.format(self.epoch, loss))\n",
    "        model.running_training_loss = 0.0\n",
    "        self.epoch = self.epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61e8337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.025>', 'datetime': '2023-04-22T18:18:42.284078', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(vector_size=100, window=3, min_count=10, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35054bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence('sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "615cf92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #5000000, processed 44754492 words, keeping 895623 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000000, processed 89584467 words, keeping 1350126 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #15000000, processed 134296356 words, keeping 1699597 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000000, processed 179110867 words, keeping 1997894 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #25000000, processed 223797301 words, keeping 2271233 word types\n",
      "INFO:gensim.models.word2vec:collected 2286211 word types from a corpus of 226493880 raw words and 25306752 sentences\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 328798 unique words (14.38% of original 2286211, drops 1957413)', 'datetime': '2023-04-22T18:20:06.113781', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 222510576 word corpus (98.24% of original 226493880, drops 3983304)', 'datetime': '2023-04-22T18:20:06.114500', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 2286211 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 8 most-common words\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 220061146.27766725 word corpus (98.9%% of prior 222510576)', 'datetime': '2023-04-22T18:20:07.308636', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:estimated required memory for 328798 words and 100 dimensions: 427437400 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-22T18:20:09.614386', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences, progress_per=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "867dc13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 5 workers on 328798 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=3 shrink_windows=True', 'datetime': '2023-04-22T18:20:09.631800', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 0.58% examples, 1265770 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 47.87% examples, 871369 words/s, in_qsize 10, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 94.48% examples, 861497 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 0: training on 226493880 raw words (220063745 effective words) took 250.9s, 877088 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:45268440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 0.57% examples, 1243133 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 52.18% examples, 949579 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1: training on 226493880 raw words (220060555 effective words) took 230.1s, 956426 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1:43138140.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 0.50% examples, 89227 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 48.43% examples, 806345 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 98.56% examples, 859817 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 2: training on 226493880 raw words (220059964 effective words) took 254.7s, 864026 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 2:43365704.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 0.59% examples, 1293767 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 50.86% examples, 925457 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 94.14% examples, 860057 words/s, in_qsize 8, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 3: training on 226493880 raw words (220059516 effective words) took 266.8s, 824842 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 3:43203232.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 0.55% examples, 1212459 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 46.38% examples, 844114 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 92.76% examples, 847382 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4: training on 226493880 raw words (220060783 effective words) took 253.2s, 869252 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 4:43267796.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 0.59% examples, 1275981 words/s, in_qsize 9, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 44.46% examples, 809298 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 87.13% examples, 795900 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5: training on 226493880 raw words (220060660 effective words) took 275.9s, 797644 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 5:43275668.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 0.50% examples, 1087045 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 48.90% examples, 890095 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 96.07% examples, 877607 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6: training on 226493880 raw words (220061714 effective words) took 248.0s, 887471 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 6:43009856.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 0.56% examples, 1221637 words/s, in_qsize 10, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 46.54% examples, 847129 words/s, in_qsize 8, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 93.88% examples, 832538 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 7: training on 226493880 raw words (220060657 effective words) took 258.7s, 850617 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 7:43133328.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 0.59% examples, 1298293 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 48.26% examples, 878538 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 97.50% examples, 890529 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8: training on 226493880 raw words (220060562 effective words) took 245.1s, 897953 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 8:43170964.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 0.10% examples, 13837 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 45.62% examples, 734035 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 93.24% examples, 799107 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9: training on 226493880 raw words (220059147 effective words) took 268.0s, 820976 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 9:43238204.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 0.60% examples, 1308078 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 49.91% examples, 908283 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 97.06% examples, 880735 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10: training on 226493880 raw words (220059421 effective words) took 247.7s, 888543 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 10:42894520.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 0.61% examples, 1319431 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 53.17% examples, 967389 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 11: training on 226493880 raw words (220061907 effective words) took 236.0s, 932398 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 11:43087872.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 0.56% examples, 1232022 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 46.11% examples, 839339 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 94.16% examples, 841749 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 12: training on 226493880 raw words (220061540 effective words) took 256.2s, 858805 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 12:42866644.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 0.61% examples, 1328466 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 51.30% examples, 933569 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 96.23% examples, 879017 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 13: training on 226493880 raw words (220059684 effective words) took 247.7s, 888510 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 13:42945276.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 0.58% examples, 1266587 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 45.26% examples, 823850 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 91.75% examples, 809636 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 14: training on 226493880 raw words (220060655 effective words) took 263.6s, 834964 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 14:42836076.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 0.56% examples, 1227227 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 50.69% examples, 922381 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 15: training on 226493880 raw words (220059199 effective words) took 234.4s, 939005 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 15:42672528.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 0.58% examples, 1271720 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 58.09% examples, 998106 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 16: training on 226493880 raw words (220060059 effective words) took 213.4s, 1031283 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 16:42711492.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 0.59% examples, 1273395 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 52.97% examples, 963624 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 17: training on 226493880 raw words (220061066 effective words) took 222.5s, 989220 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 17:42722508.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 0.58% examples, 1241038 words/s, in_qsize 8, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 54.73% examples, 984304 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 18: training on 226493880 raw words (220062642 effective words) took 216.1s, 1018454 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 18:42639984.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 0.46% examples, 125420 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 49.07% examples, 843882 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 19: training on 226493880 raw words (220060398 effective words) took 240.5s, 914918 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 19:42465852.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 20 - PROGRESS: at 0.58% examples, 1260218 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 20 - PROGRESS: at 52.28% examples, 911889 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 20: training on 226493880 raw words (220060649 effective words) took 234.0s, 940524 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 20:42260604.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 21 - PROGRESS: at 0.58% examples, 1272070 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 21 - PROGRESS: at 55.83% examples, 1015711 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 21: training on 226493880 raw words (220061662 effective words) took 226.8s, 970491 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 21:42219876.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 22 - PROGRESS: at 0.56% examples, 1223068 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 22 - PROGRESS: at 47.99% examples, 873623 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 22 - PROGRESS: at 96.26% examples, 879207 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 22: training on 226493880 raw words (220061192 effective words) took 247.2s, 890199 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 22:42389964.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 23 - PROGRESS: at 0.60% examples, 1309848 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 23 - PROGRESS: at 50.56% examples, 920023 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 23 - PROGRESS: at 97.82% examples, 893390 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 23: training on 226493880 raw words (220060715 effective words) took 244.6s, 899777 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 23:42439336.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 24 - PROGRESS: at 0.58% examples, 1275790 words/s, in_qsize 9, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 24 - PROGRESS: at 46.48% examples, 813504 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 24 - PROGRESS: at 92.07% examples, 808713 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 24: training on 226493880 raw words (220062316 effective words) took 264.2s, 833034 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 24:42179860.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 25 - PROGRESS: at 0.58% examples, 1275888 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 25 - PROGRESS: at 52.30% examples, 951735 words/s, in_qsize 10, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 25 - PROGRESS: at 99.93% examples, 912374 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 25: training on 226493880 raw words (220062232 effective words) took 241.1s, 912718 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 25:41902724.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 26 - PROGRESS: at 0.57% examples, 1246414 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 26 - PROGRESS: at 56.90% examples, 1035495 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 26: training on 226493880 raw words (220061982 effective words) took 225.0s, 978055 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 26:41855820.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 27 - PROGRESS: at 0.58% examples, 1261506 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 27 - PROGRESS: at 50.54% examples, 919566 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 27: training on 226493880 raw words (220060632 effective words) took 225.3s, 976904 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 27:41842668.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 28 - PROGRESS: at 0.60% examples, 1299587 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 28 - PROGRESS: at 55.18% examples, 1002824 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 28: training on 226493880 raw words (220061776 effective words) took 211.8s, 1039046 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 28:41812468.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 29 - PROGRESS: at 0.50% examples, 116976 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 29 - PROGRESS: at 58.96% examples, 1003941 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 29: training on 226493880 raw words (220061505 effective words) took 220.1s, 999767 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 29:41615648.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 30 - PROGRESS: at 0.59% examples, 1302219 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 30 - PROGRESS: at 54.70% examples, 995179 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 30: training on 226493880 raw words (220062507 effective words) took 218.4s, 1007727 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 30:41400372.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 31 - PROGRESS: at 0.59% examples, 1294298 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 31 - PROGRESS: at 57.63% examples, 1008364 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 31: training on 226493880 raw words (220059280 effective words) took 212.3s, 1036526 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 31:41358844.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 32 - PROGRESS: at 0.58% examples, 1271148 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 32 - PROGRESS: at 52.10% examples, 948235 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 32: training on 226493880 raw words (220061779 effective words) took 227.2s, 968598 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 32:41316156.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 33 - PROGRESS: at 0.60% examples, 1320115 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 33 - PROGRESS: at 56.86% examples, 1001525 words/s, in_qsize 0, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 33: training on 226493880 raw words (220060063 effective words) took 214.2s, 1027160 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 33:41630256.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 34 - PROGRESS: at 0.59% examples, 1287644 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 34 - PROGRESS: at 52.80% examples, 960586 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 34: training on 226493880 raw words (220061676 effective words) took 223.0s, 986976 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 34:41005404.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 35 - PROGRESS: at 0.56% examples, 1223993 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 35 - PROGRESS: at 53.73% examples, 975067 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 35: training on 226493880 raw words (220060685 effective words) took 223.5s, 984486 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 35:40615628.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 36 - PROGRESS: at 0.58% examples, 1259395 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 36 - PROGRESS: at 58.32% examples, 1061194 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 36: training on 226493880 raw words (220059501 effective words) took 215.8s, 1019680 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 36:40720424.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 37 - PROGRESS: at 0.59% examples, 1277408 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 37 - PROGRESS: at 52.89% examples, 962173 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 37: training on 226493880 raw words (220059742 effective words) took 222.2s, 990218 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 37:40630364.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 38 - PROGRESS: at 0.58% examples, 1263078 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 38 - PROGRESS: at 53.46% examples, 972729 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 38: training on 226493880 raw words (220062869 effective words) took 234.2s, 939528 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 38:40324520.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 39 - PROGRESS: at 0.58% examples, 1262008 words/s, in_qsize 8, out_qsize 3\n",
      "INFO:gensim.models.word2vec:EPOCH 39 - PROGRESS: at 47.25% examples, 857253 words/s, in_qsize 10, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 39: training on 226493880 raw words (220061227 effective words) took 233.3s, 943228 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 39:39965872.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 40 - PROGRESS: at 0.58% examples, 1256256 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 40 - PROGRESS: at 53.27% examples, 963383 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 40: training on 226493880 raw words (220063137 effective words) took 222.1s, 990625 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 40:39781376.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 41 - PROGRESS: at 0.51% examples, 1113402 words/s, in_qsize 9, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 41 - PROGRESS: at 57.75% examples, 1051164 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 41: training on 226493880 raw words (220061256 effective words) took 214.7s, 1024903 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 41:39536580.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 42 - PROGRESS: at 0.58% examples, 1250310 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 42 - PROGRESS: at 53.78% examples, 978446 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 42: training on 226493880 raw words (220059504 effective words) took 220.7s, 997316 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 42:39529876.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 43 - PROGRESS: at 0.58% examples, 1269776 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 43 - PROGRESS: at 55.70% examples, 971662 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 43: training on 226493880 raw words (220060495 effective words) took 220.0s, 1000260 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 43:39245684.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 44 - PROGRESS: at 0.58% examples, 1277479 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 44 - PROGRESS: at 47.86% examples, 871290 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 44: training on 226493880 raw words (220060363 effective words) took 235.8s, 933304 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 44:38712500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 45 - PROGRESS: at 0.57% examples, 1252417 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 45 - PROGRESS: at 52.25% examples, 915032 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 45: training on 226493880 raw words (220058813 effective words) took 233.8s, 941074 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 45:38622580.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 46 - PROGRESS: at 0.58% examples, 1271261 words/s, in_qsize 8, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 46 - PROGRESS: at 56.13% examples, 1021113 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 46: training on 226493880 raw words (220061384 effective words) took 223.9s, 982992 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 46:38158500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 47 - PROGRESS: at 0.58% examples, 1274743 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 47 - PROGRESS: at 49.69% examples, 904118 words/s, in_qsize 9, out_qsize 1\n",
      "INFO:gensim.models.word2vec:EPOCH 47: training on 226493880 raw words (220062300 effective words) took 235.1s, 936178 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 47:37891508.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 48 - PROGRESS: at 0.60% examples, 1295986 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 48 - PROGRESS: at 51.80% examples, 942646 words/s, in_qsize 9, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 48: training on 226493880 raw words (220061289 effective words) took 229.5s, 959054 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 48:37483072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 49 - PROGRESS: at 0.55% examples, 116964 words/s, in_qsize 8, out_qsize 2\n",
      "INFO:gensim.models.word2vec:EPOCH 49 - PROGRESS: at 53.21% examples, 899569 words/s, in_qsize 10, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 49: training on 226493880 raw words (220060630 effective words) took 242.2s, 908436 effective words/s\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 11324694000 raw words (11003047035 effective words) took 11771.5s, 934723 effective words/s', 'datetime': '2023-04-22T23:13:31.550670', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 49:37343080.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11003047035, 11324694000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, epochs=50, total_examples=model.corpus_count, total_words=model.corpus_total_words, compute_loss=True, report_delay=120, callbacks=[Callback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec534c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname_or_handle': 'word2vec-100-bel-cc100.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-23T01:10:15.447782', 'gensim': '4.3.1', 'python': '3.11.3 | packaged by conda-forge | (main, Apr  6 2023, 09:05:00) [Clang 14.0.6 ]', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'event': 'saving'}\n",
      "INFO:gensim.utils:storing np array 'vectors' to word2vec-100-bel-cc100.model.wv.vectors.npy\n",
      "INFO:gensim.utils:storing np array 'syn1neg' to word2vec-100-bel-cc100.model.syn1neg.npy\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "INFO:gensim.utils:saved word2vec-100-bel-cc100.model\n"
     ]
    }
   ],
   "source": [
    "model.save(\"word2vec-100-bel-cc100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "625cd5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('мядзведзь', 0.7393637895584106),\n",
       " ('звер', 0.7242729067802429),\n",
       " ('заяц', 0.7042849063873291),\n",
       " ('бык', 0.6875906586647034),\n",
       " ('муха', 0.6802892684936523),\n",
       " ('драпежнік', 0.6730962991714478),\n",
       " ('кабан', 0.6689190864562988),\n",
       " ('алень', 0.6683720350265503),\n",
       " ('выгаладаўся', 0.656315803527832),\n",
       " ('варона', 0.6556535363197327),\n",
       " ('змей', 0.6529685854911804),\n",
       " ('сабака', 0.6515656113624573),\n",
       " ('табун', 0.6455168724060059),\n",
       " ('драпежны', 0.6449723243713379),\n",
       " ('мураш', 0.6393277049064636),\n",
       " ('лісіца', 0.633025586605072),\n",
       " ('жаба', 0.6329237818717957),\n",
       " ('курапатка', 0.6244716644287109),\n",
       " ('вуж', 0.6240508556365967),\n",
       " ('конь', 0.6231964230537415)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('воўк', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "465b441c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['год',\n",
       " 'беларускі',\n",
       " 'чалавек',\n",
       " 'беларусі',\n",
       " 'час',\n",
       " 'дзень',\n",
       " 'больш',\n",
       " 'мова',\n",
       " 'новы',\n",
       " 'беларусь',\n",
       " 'вялікі',\n",
       " 'краіна',\n",
       " 'жыццё',\n",
       " 'праца',\n",
       " 'горад',\n",
       " 'месца',\n",
       " 'справа',\n",
       " 'гісторыя',\n",
       " 'рэспубліка',\n",
       " 'слова',\n",
       " 'кожны',\n",
       " 'гульня',\n",
       " 'дзіцё',\n",
       " 'дзяржаўны',\n",
       " 'сайт',\n",
       " 'нацыянальны',\n",
       " 'раён',\n",
       " 'пытанне',\n",
       " 'імя',\n",
       " 'галоўны',\n",
       " 'свет',\n",
       " 'культура',\n",
       " 'кніга',\n",
       " 'старонка',\n",
       " 'раз',\n",
       " 'другі',\n",
       " 'розны',\n",
       " 'адзін',\n",
       " 'арганізацыя',\n",
       " 'школа',\n",
       " 'апошні',\n",
       " 'дом',\n",
       " 'цэнтр',\n",
       " 'матэрыял',\n",
       " 'вынік',\n",
       " 'правіць',\n",
       " 'праект',\n",
       " 'цяпер',\n",
       " 'беларус',\n",
       " 'права',\n",
       " 'адукацыя',\n",
       " 'вайна',\n",
       " 'частка',\n",
       " 'праграма',\n",
       " 'дзяржава',\n",
       " 'зямля',\n",
       " 'шмат',\n",
       " 'міжнародны',\n",
       " 'сёння',\n",
       " 'гад',\n",
       " 'работа',\n",
       " 'інфармацыя',\n",
       " 'развіццё',\n",
       " 'выбар',\n",
       " 'няма',\n",
       " 'лепшы',\n",
       " 'народны',\n",
       " 'наступны',\n",
       " 'палітычны',\n",
       " 'іншых',\n",
       " 'праблема',\n",
       " 'пачатак',\n",
       " 'вёска',\n",
       " 'народ',\n",
       " 'кіраўнік',\n",
       " 'мяжа',\n",
       " 'стол',\n",
       " 'літаратура',\n",
       " 'артыкул',\n",
       " 'бацька',\n",
       " 'дзейнасць',\n",
       " 'магчымасць',\n",
       " 'выпадак',\n",
       " 'дапамога',\n",
       " 'бок',\n",
       " 'вобласць',\n",
       " 'асноўны',\n",
       " 'выкарыстанне',\n",
       " 'сябар',\n",
       " 'аўтар',\n",
       " 'добры',\n",
       " 'кампанія',\n",
       " 'першае',\n",
       " 'колькасць',\n",
       " 'некалькі',\n",
       " 'суд',\n",
       " 'сучасны',\n",
       " 'мясцовы',\n",
       " 'сістэма',\n",
       " 'прадстаўнік',\n",
       " 'тэрыторыя',\n",
       " 'сярод',\n",
       " 'малады',\n",
       " 'любы',\n",
       " 'прэзідэнт',\n",
       " 'музей',\n",
       " 'многі',\n",
       " 'свабода',\n",
       " 'жанчына',\n",
       " 'старшыня',\n",
       " 'два',\n",
       " 'іншыя',\n",
       " 'навука',\n",
       " 'савет',\n",
       " 'спасылка',\n",
       " 'лік',\n",
       " 'рука',\n",
       " 'група',\n",
       " 'сказ',\n",
       " 'крыніца',\n",
       " 'родны',\n",
       " 'некаторыя',\n",
       " 'мастацтва',\n",
       " 'сустрэча',\n",
       " 'конкурс',\n",
       " 'сіла',\n",
       " 'польскі',\n",
       " 'назва',\n",
       " 'грамадскі',\n",
       " 'супраць',\n",
       " 'тэма',\n",
       " 'інтэрнэт',\n",
       " 'першы',\n",
       " 'царква',\n",
       " 'дадзены',\n",
       " 'яўляецца',\n",
       " 'падзея',\n",
       " 'тысяча',\n",
       " 'мерапрыемства',\n",
       " 'твор',\n",
       " 'шлях',\n",
       " 'гістарычны',\n",
       " 'мэта',\n",
       " 'рашэнне',\n",
       " 'якасць',\n",
       " 'клас',\n",
       " 'савецкі',\n",
       " 'газета',\n",
       " 'бібліятэка',\n",
       " 'сувязь',\n",
       " 'рэч',\n",
       " 'зрабіць',\n",
       " 'радыё',\n",
       " 'стагоддзе',\n",
       " 'вядомы',\n",
       " 'палітык',\n",
       " 'агульны',\n",
       " 'студэнт',\n",
       " 'сакавік',\n",
       " 'партыя',\n",
       " 'відэа',\n",
       " 'пісьменнік',\n",
       " 'месяц',\n",
       " 'сын',\n",
       " 'міністр',\n",
       " 'бог',\n",
       " 'рух',\n",
       " 'сацыяльны',\n",
       " 'працэс',\n",
       " 'жыхар',\n",
       " 'сродак',\n",
       " 'пакуль',\n",
       " 'акцыя',\n",
       " 'склад',\n",
       " 'заўсёды',\n",
       " 'стан',\n",
       " 'сітуацыя',\n",
       " 'катэгорыя',\n",
       " 'вуліца',\n",
       " 'галіна',\n",
       " 'тыдзень',\n",
       " 'момант',\n",
       " 'канец',\n",
       " 'сярэдні',\n",
       " 'мінскі',\n",
       " 'форма',\n",
       " 'міністэрства',\n",
       " 'добра',\n",
       " 'святы',\n",
       " 'улада',\n",
       " 'кастрычнік',\n",
       " 'тры',\n",
       " 'адказ',\n",
       " 'павінны',\n",
       " 'свята',\n",
       " 'мінулы',\n",
       " 'эканамічны',\n",
       " 'аляксандр',\n",
       " 'гадзіна',\n",
       " 'тэкст',\n",
       " 'усё',\n",
       " 'высокі',\n",
       " 'саюз',\n",
       " 'закон',\n",
       " 'асоба',\n",
       " 'рускі',\n",
       " 'думка',\n",
       " 'ліпень',\n",
       " 'верш',\n",
       " 'выданне',\n",
       " 'нашы',\n",
       " 'мінску',\n",
       " 'лістапад',\n",
       " 'культурны',\n",
       " 'стары',\n",
       " 'верасень',\n",
       " 'аднаго',\n",
       " 'грамадзянін',\n",
       " 'зыходнік',\n",
       " 'насельніцтва',\n",
       " 'стаў',\n",
       " 'маці',\n",
       " 'сусветны',\n",
       " 'лукашэнка',\n",
       " 'паэт',\n",
       " 'курс',\n",
       " 'працяг',\n",
       " 'раней',\n",
       " 'даль',\n",
       " 'дзіцячы',\n",
       " 'вядома',\n",
       " 'раённы',\n",
       " 'праўда',\n",
       " 'замежны',\n",
       " 'акрамя',\n",
       " 'кажа',\n",
       " 'маюць',\n",
       " 'стварэнне',\n",
       " 'мастацкі',\n",
       " 'адносіна',\n",
       " 'рабіць',\n",
       " 'песня',\n",
       " 'дакумент',\n",
       " 'журналіст',\n",
       " 'вада',\n",
       " 'касцёл',\n",
       " 'падтрымка',\n",
       " 'камітэт',\n",
       " 'расійскі',\n",
       " 'гарадскі',\n",
       " 'афіцыйны',\n",
       " 'зша',\n",
       " 'студзень',\n",
       " 'навіна',\n",
       " 'навуковы',\n",
       " 'варта',\n",
       " 'музыка',\n",
       " 'дзеянне',\n",
       " 'часопіс',\n",
       " 'цікавы',\n",
       " 'нічога',\n",
       " 'чэрвень',\n",
       " 'поўны',\n",
       " 'служба',\n",
       " 'правы',\n",
       " 'прычына',\n",
       " 'белы',\n",
       " 'правіла',\n",
       " 'асабліва',\n",
       " 'удзел',\n",
       " 'красавік',\n",
       " 'менш',\n",
       " 'моладзь',\n",
       " 'асобны',\n",
       " 'правядзенне',\n",
       " 'файл',\n",
       " 'даследаванне',\n",
       " 'чат',\n",
       " 'інстытут',\n",
       " 'камісія',\n",
       " 'вучань',\n",
       " 'ідэя',\n",
       " 'памяць',\n",
       " 'адзіны',\n",
       " 'з’яўляецца',\n",
       " 'адна',\n",
       " 'будынак',\n",
       " 'гэтая',\n",
       " 'змена',\n",
       " 'пункт',\n",
       " 'люты',\n",
       " 'падобны',\n",
       " 'прадпрыемства',\n",
       " 'пэўны',\n",
       " 'онлайн',\n",
       " 'жнівень',\n",
       " 'расейскі',\n",
       " 'ліст',\n",
       " 'абарона',\n",
       " 'літоўскі',\n",
       " 'адной',\n",
       " 'рубель',\n",
       " 'навучанне',\n",
       " 'сапраўдны',\n",
       " 'установа',\n",
       " 'кандыдат',\n",
       " 'беларуска',\n",
       " 'мінск',\n",
       " 'веды',\n",
       " 'супрацоўнік',\n",
       " 'расіі',\n",
       " 'намеснік',\n",
       " 'удзельнік',\n",
       " 'знаходзіцца',\n",
       " 'важны',\n",
       " 'годдзе',\n",
       " 'дарога',\n",
       " 'выстава',\n",
       " 'былы',\n",
       " 'здароўе',\n",
       " 'магчыма',\n",
       " 'менску',\n",
       " 'выгляд',\n",
       " 'каманда',\n",
       " 'тэрмін',\n",
       " 'рэгіён',\n",
       " 'атрымаць',\n",
       " 'помнік',\n",
       " 'польшчы',\n",
       " 'абласны',\n",
       " 'ўсім',\n",
       " 'універсітэт',\n",
       " 'вока',\n",
       " 'від',\n",
       " 'альбо',\n",
       " 'павінна',\n",
       " 'еўрапейскі',\n",
       " 'дэпутат',\n",
       " 'тэатр',\n",
       " 'снежань',\n",
       " 'рэдагаваць',\n",
       " 'перыяд',\n",
       " 'грош',\n",
       " 'гаспадарка',\n",
       " 'сваё',\n",
       " 'фота',\n",
       " 'найбольш',\n",
       " 'грамадства',\n",
       " 'кошт',\n",
       " 'творчасць',\n",
       " 'заходні',\n",
       " 'гэтую',\n",
       " 'неабходны',\n",
       " 'фестываль',\n",
       " 'мастак',\n",
       " 'большасць',\n",
       " 'план',\n",
       " 'плошча',\n",
       " 'творчы',\n",
       " 'воля',\n",
       " 'гісторык',\n",
       " 'сэрца',\n",
       " 'малы',\n",
       " 'цалок',\n",
       " 'працоўны',\n",
       " 'дадатковы',\n",
       " 'дырэктар',\n",
       " 'літаратурны',\n",
       " 'працаваць',\n",
       " 'нараджэнне',\n",
       " 'перамога',\n",
       " 'часта',\n",
       " 'актыўны',\n",
       " 'маг',\n",
       " 'захад',\n",
       " 'орган',\n",
       " 'фільм',\n",
       " 'сапраўды',\n",
       " 'адкрыты',\n",
       " 'усіх',\n",
       " 'доўгі',\n",
       " 'бясплатны',\n",
       " 'такой',\n",
       " 'аснова',\n",
       " 'такое',\n",
       " 'знайсці',\n",
       " 'падрыхтоўка',\n",
       " 'павінен',\n",
       " 'ўдзел',\n",
       " 'цябе',\n",
       " 'невялікі',\n",
       " 'аддзел',\n",
       " 'актывіст',\n",
       " 'мужчына',\n",
       " 'шэраг',\n",
       " 'мой',\n",
       " 'спіс',\n",
       " 'кіраўніцтва',\n",
       " 'ахова',\n",
       " 'папярэдні',\n",
       " 'нешта',\n",
       " 'ніколі',\n",
       " 'факт',\n",
       " 'рэжым',\n",
       " 'парадак',\n",
       " 'увага',\n",
       " 'сталь',\n",
       " 'прыклад',\n",
       " 'сказаць',\n",
       " 'традыцыя',\n",
       " 'паслуга',\n",
       " 'уладзімір',\n",
       " 'жонка',\n",
       " 'госць',\n",
       " 'герой',\n",
       " 'cookіes',\n",
       " 'мець',\n",
       " 'цэлы',\n",
       " 'рэспубліканскі',\n",
       " 'вясна',\n",
       " 'настаўнік',\n",
       " 'роля',\n",
       " 'першай',\n",
       " 'электронны',\n",
       " 'будаўніцтва',\n",
       " 'эканоміка',\n",
       " 'дзяўчына',\n",
       " 'спецыяліст',\n",
       " 'значны',\n",
       " 'адбылося',\n",
       " 'цэнтральны',\n",
       " 'хутка',\n",
       " 'май',\n",
       " 'неба',\n",
       " 'пераклад',\n",
       " 'неабходна',\n",
       " 'душ',\n",
       " 'праваслаўны',\n",
       " 'ніхто',\n",
       " 'божы',\n",
       " 'вышэйшы',\n",
       " 'прэмія',\n",
       " 'канферэнцыя',\n",
       " 'вытворчасць',\n",
       " 'задача',\n",
       " 'чырвоны',\n",
       " 'войска',\n",
       " 'масавы',\n",
       " 'украіны',\n",
       " 'сяргей',\n",
       " 'сфера',\n",
       " 'клуб',\n",
       " 'атрымаў',\n",
       " 'ступень',\n",
       " 'спадчына',\n",
       " 'самых',\n",
       " 'асобы',\n",
       " 'прысвечаны',\n",
       " 'сабой',\n",
       " 'прэс',\n",
       " 'брат',\n",
       " 'палова',\n",
       " 'канцэрт',\n",
       " 'працуе',\n",
       " 'прафесійны',\n",
       " 'нямецкі',\n",
       " 'ўлады',\n",
       " 'рэгістрацыя',\n",
       " 'нумар',\n",
       " 'колька',\n",
       " 'незалежнасць',\n",
       " 'музычны',\n",
       " 'ваенны',\n",
       " 'варыянт',\n",
       " 'смерць',\n",
       " 'ласка',\n",
       " 'каталіцкі',\n",
       " 'князь',\n",
       " 'кіраванне',\n",
       " 'рынак',\n",
       " 'вікіпедыя',\n",
       " 'акадэмія',\n",
       " 'край',\n",
       " 'значэнне',\n",
       " 'ноч',\n",
       " 'пара',\n",
       " 'адно',\n",
       " 'віцебскі',\n",
       " 'ўмовы',\n",
       " 'сваімі',\n",
       " 'дзякуючы',\n",
       " 'адрас',\n",
       " 'выкананне',\n",
       " 'майстар',\n",
       " 'паветра',\n",
       " 'сход',\n",
       " 'лес',\n",
       " 'член',\n",
       " 'княства',\n",
       " 'любоў',\n",
       " 'звязаны',\n",
       " 'умова',\n",
       " 'такая',\n",
       " 'нарадзіўся',\n",
       " 'тэхнічны',\n",
       " 'рацыя',\n",
       " 'асабісты',\n",
       " 'блізкі',\n",
       " 'тэмпература',\n",
       " 'чарга',\n",
       " 'тэхналогія',\n",
       " 'калектыў',\n",
       " 'парушэнне',\n",
       " 'значыць',\n",
       " 'атрыманне',\n",
       " 'моцны',\n",
       " 'голас',\n",
       " 'дарэчы',\n",
       " 'грамадзянскі',\n",
       " 'двух',\n",
       " 'ідзе',\n",
       " 'супрацоўніцтва',\n",
       " 'навучальны',\n",
       " 'пасад',\n",
       " 'вера',\n",
       " 'лічыць',\n",
       " 'выбарчы',\n",
       " 'размова',\n",
       " 'міліцыя',\n",
       " 'гурт',\n",
       " 'сетка',\n",
       " 'рэсурс',\n",
       " 'супольнасць',\n",
       " 'сельскі',\n",
       " 'запіс',\n",
       " 'сталіца',\n",
       " 'c',\n",
       " 'лепш',\n",
       " 'дума',\n",
       " 'база',\n",
       " 'жывы',\n",
       " 'крымінальны',\n",
       " 'работнік',\n",
       " 'праваабаронца',\n",
       " 'большы',\n",
       " 'інфармацыйны',\n",
       " 'бяспека',\n",
       " 'барацьба',\n",
       " 'небудзь',\n",
       " 'галава',\n",
       " 'збор',\n",
       " 'хвіліна',\n",
       " 'элемент',\n",
       " 'таварыства',\n",
       " 'рака',\n",
       " 'прырода',\n",
       " 'хата',\n",
       " 'патрэбны',\n",
       " 'прадукт',\n",
       " 'маленькі',\n",
       " 'незалежны',\n",
       " 'стварыць',\n",
       " 'публікацыя',\n",
       " 'дзеяч',\n",
       " 'паўночны',\n",
       " 'андрэй',\n",
       " 'прыгожы',\n",
       " 'расеі',\n",
       " 'машына',\n",
       " 'памер',\n",
       " 'кватэра',\n",
       " 'сэнс',\n",
       " 'узровень',\n",
       " 'пошук',\n",
       " 'чорны',\n",
       " 'адпаведны',\n",
       " 'нельга',\n",
       " 'хуткасць',\n",
       " 'банк',\n",
       " 'гадовы',\n",
       " 'надвор',\n",
       " 'шырокі',\n",
       " 'бізнес',\n",
       " 'лёс',\n",
       " 'прапанова',\n",
       " 'чытач',\n",
       " 'поспех',\n",
       " 'такога',\n",
       " 'бясплатна',\n",
       " 'айчынны',\n",
       " 'род',\n",
       " 'зварот',\n",
       " 'начальнік',\n",
       " 'дзве',\n",
       " 'шматлікі',\n",
       " 'даволі',\n",
       " 'стаць',\n",
       " 'гатовы',\n",
       " 'замак',\n",
       " 'прадукцыя',\n",
       " 'характар',\n",
       " 'мог',\n",
       " 'выдатны',\n",
       " 'просты',\n",
       " 'адкрыццё',\n",
       " 'гонар',\n",
       " 'сезон',\n",
       " 'будучы',\n",
       " 'жыць',\n",
       " 'працаваў',\n",
       " 'адзначыў',\n",
       " 'чарговы',\n",
       " 'спартыўны',\n",
       " 'заява',\n",
       " 'пакаранне',\n",
       " 'ініцыятыва',\n",
       " 'магілёўскі',\n",
       " 'адпачынак',\n",
       " 'даступны',\n",
       " 'знак',\n",
       " 'створаны',\n",
       " 'ўмовах',\n",
       " 'спецыяльны',\n",
       " 'спачатку',\n",
       " 'дрэва',\n",
       " 'пачалі',\n",
       " 'ссср',\n",
       " 'дачыненне',\n",
       " 'звычайны',\n",
       " 'самым',\n",
       " 'вечар',\n",
       " 'патрабаванне',\n",
       " 'парк',\n",
       " 'каштоўнасць',\n",
       " 'адказнасць',\n",
       " 'рэдактар',\n",
       " 'ўсяго',\n",
       " 'сцяг',\n",
       " 'асаблівы',\n",
       " 'армія',\n",
       " 'погляд',\n",
       " 'папулярны',\n",
       " 'аляксандра',\n",
       " 'дае',\n",
       " 'жыве',\n",
       " 'факультэт',\n",
       " 'кропка',\n",
       " 'спорт',\n",
       " 'дэмакратычны',\n",
       " 'абавязковы',\n",
       " 'нягледзячы',\n",
       " 'стыль',\n",
       " 'крок',\n",
       " 'заявіў',\n",
       " 'сям',\n",
       " 'тэлефон',\n",
       " 'штат',\n",
       " 'сённяшні',\n",
       " 'раман',\n",
       " 'занятак',\n",
       " 'рамка',\n",
       " 'сёлета',\n",
       " 'крама',\n",
       " 'этап',\n",
       " 'комплекс',\n",
       " 'гродзенскі',\n",
       " 'падстава',\n",
       " 'адміністрацыйны',\n",
       " 'браўзер',\n",
       " 'маглі',\n",
       " 'прадмет',\n",
       " 'побач',\n",
       " 'карт',\n",
       " 'поле',\n",
       " 'вопыт',\n",
       " 'адбудзецца',\n",
       " 'меркаванне',\n",
       " 'ваш',\n",
       " 'лінія',\n",
       " 'пачаў',\n",
       " 'мільён',\n",
       " 'трох',\n",
       " 'мера',\n",
       " 'цяжка',\n",
       " 'хаця',\n",
       " 'жывёла',\n",
       " 'фонд',\n",
       " 'будзем',\n",
       " 'зала',\n",
       " 'колер',\n",
       " 'кажуць',\n",
       " 'купал',\n",
       " 'лета',\n",
       " 'адбываецца',\n",
       " 'дзяўчынка',\n",
       " 'дазваляе',\n",
       " 'завод',\n",
       " 'цяжкі',\n",
       " 'таб',\n",
       " 'духоўны',\n",
       " 'прыватнасць',\n",
       " 'хутчэй',\n",
       " 'смі',\n",
       " 'спосаб',\n",
       " 'першыя',\n",
       " 'асаблівасць',\n",
       " 'адбылася',\n",
       " 'прыватны',\n",
       " 'прынцып',\n",
       " 'сям’і',\n",
       " 'старажытны',\n",
       " 'намі',\n",
       " 'самыя',\n",
       " 'цяперашні',\n",
       " 'рады',\n",
       " 'зборнік',\n",
       " 'існуе',\n",
       " 'пазней',\n",
       " 'хлопец',\n",
       " 'заканадаўства',\n",
       " 'птушка',\n",
       " 'інш',\n",
       " 'дачка',\n",
       " 'цела',\n",
       " 'дух',\n",
       " 'традыцыйны',\n",
       " 'сцяна',\n",
       " 'затым',\n",
       " 'арганізатар',\n",
       " 'магчымы',\n",
       " 'звычайна',\n",
       " 'значна',\n",
       " 'інтарэс',\n",
       " 'хрысціянскі',\n",
       " 'першая',\n",
       " 'структура',\n",
       " 'рэдакцыя',\n",
       " 'пяць',\n",
       " 'абавязкова',\n",
       " 'надзея',\n",
       " 'будучыня',\n",
       " 'атрымалі',\n",
       " 'кароткі',\n",
       " 'спампаваць',\n",
       " 'усходні',\n",
       " 'нагода',\n",
       " 'азначае',\n",
       " 'чатыры',\n",
       " 'адбыўся',\n",
       " 'буйны',\n",
       " 'здаецца',\n",
       " 'форум',\n",
       " 'радзіма',\n",
       " 'даўно',\n",
       " 'рост',\n",
       " 'самае',\n",
       " 'райвыканкам',\n",
       " 'хатні',\n",
       " 'палац',\n",
       " 'адміністрацыя',\n",
       " 'пакаленне',\n",
       " 'патрэба',\n",
       " 'еўропы',\n",
       " '№',\n",
       " 'пазіцыя',\n",
       " 'кантакт',\n",
       " 'меў',\n",
       " 'раніца',\n",
       " 'пакой',\n",
       " 'адпаведнасць',\n",
       " 'гэтак',\n",
       " 'мікалай',\n",
       " 'іншым',\n",
       " 'тып',\n",
       " 'гуляць',\n",
       " 'максім',\n",
       " 'памяшканне',\n",
       " 'алесь',\n",
       " 'ведаць',\n",
       " 'выраб',\n",
       " 'жаданне',\n",
       " 'маскоўскі',\n",
       " 'бсср',\n",
       " 'чалавечы',\n",
       " 'складаны',\n",
       " 'першую',\n",
       " 'храм',\n",
       " 'пляцоўка',\n",
       " 'пройда',\n",
       " 'пастанова',\n",
       " 'кантроль',\n",
       " 'паўднёвы',\n",
       " 'прэзентацыя',\n",
       " 'мінска',\n",
       " 'сама',\n",
       " 'запрашаем',\n",
       " 'паведамленне',\n",
       " 'размешчаны',\n",
       " 'далейшы',\n",
       " 'муж',\n",
       " 'вэб',\n",
       " 'астатні',\n",
       " 'версія',\n",
       " 'ахвяра',\n",
       " 'нага',\n",
       " 'травень',\n",
       " 'аўтамабіль',\n",
       " 'пераможца',\n",
       " 'праверка',\n",
       " 'германій',\n",
       " 'лёгкі',\n",
       " 'ўвесь',\n",
       " 'ведаю',\n",
       " 'важна',\n",
       " 'забеспячэнне',\n",
       " 'навукова',\n",
       " 'рэалізацыя',\n",
       " 'зразумела',\n",
       " 'жаночы',\n",
       " 'рабочы',\n",
       " 'згодна',\n",
       " 'прастор',\n",
       " 'ўсёй',\n",
       " 'цікава',\n",
       " 'колас',\n",
       " 'партал',\n",
       " 'цана',\n",
       " 'жаль',\n",
       " 'мала',\n",
       " 'сад',\n",
       " 'пан',\n",
       " 'юрыдычны',\n",
       " 'прамы',\n",
       " 'хочаце',\n",
       " 'вакол',\n",
       " 'тавар',\n",
       " 'тэг',\n",
       " 'рэальны',\n",
       " 'асяроддзе',\n",
       " 'застаецца',\n",
       " 'прыём',\n",
       " 'подпіс',\n",
       " 'альбом',\n",
       " 'паколькі',\n",
       " 'зона',\n",
       " 'свабодны',\n",
       " 'чыноўнік',\n",
       " 'атрымліваць',\n",
       " 'іншымі',\n",
       " 'сцэна',\n",
       " 'іншага',\n",
       " 'кветка',\n",
       " 'прайшоў',\n",
       " 'станцыя',\n",
       " 'карыстальнік',\n",
       " 'вайсковы',\n",
       " 'становішча',\n",
       " 'звестка',\n",
       " 'фронт',\n",
       " 'менскі',\n",
       " 'аддзяленне',\n",
       " 'навуковец',\n",
       " 'педагог',\n",
       " 'паэзія',\n",
       " 'распрацоўка',\n",
       " 'дата',\n",
       " 'вольны',\n",
       " 'дарослы',\n",
       " 'твар',\n",
       " 'францый',\n",
       " 'змяніць',\n",
       " 'фінансавы',\n",
       " 'педагагічны',\n",
       " 'раса',\n",
       " 'бнр',\n",
       " 'лукашэнкі',\n",
       " 'ер',\n",
       " 'найлепшы',\n",
       " 'навучэнец',\n",
       " 'сек',\n",
       " 'брэсцкі',\n",
       " 'тэхнік',\n",
       " 'змяненне',\n",
       " 'паведаміў',\n",
       " 'бак',\n",
       " 'гэту',\n",
       " 'працуюць',\n",
       " 'зрабіў',\n",
       " 'прававы',\n",
       " 'крыж',\n",
       " 'адзенне',\n",
       " 'сукенка',\n",
       " 'вобраз',\n",
       " 'ведае',\n",
       " 'школьны',\n",
       " '–',\n",
       " 'крыха',\n",
       " 'ўвагу',\n",
       " 'старэйшы',\n",
       " 'фізічны',\n",
       " 'мель',\n",
       " 'каментар',\n",
       " 'вывучэнне',\n",
       " 'памёр',\n",
       " 'доступ',\n",
       " 'пасяджэнне',\n",
       " 'віктар',\n",
       " 'эксперт',\n",
       " 'задавальненне',\n",
       " 'абавязак',\n",
       " 'зносіны',\n",
       " 'дзверы',\n",
       " 'выходзіць',\n",
       " 'турма',\n",
       " 'дапамагчы',\n",
       " 'уласны',\n",
       " 'поп',\n",
       " 'лідар',\n",
       " 'слоўнік',\n",
       " 'гомельскі',\n",
       " 'здымак',\n",
       " 'калега',\n",
       " 'адну',\n",
       " 'адукацыйны',\n",
       " 'яўляюцца',\n",
       " 'залаты',\n",
       " 'чэмпіянат',\n",
       " 'урад',\n",
       " 'бнф',\n",
       " 'вызваленне',\n",
       " 'зялёны',\n",
       " 'хоча',\n",
       " 'мадэль',\n",
       " 'чысты',\n",
       " 'нацыя',\n",
       " 'гандлёвы',\n",
       " 'радасць',\n",
       " 'выкладчык',\n",
       " 'дасягненне',\n",
       " 'пратэст',\n",
       " 'малюнак',\n",
       " 'спроба',\n",
       " 'выкарыстоўваць',\n",
       " 'вярхоўны',\n",
       " 'гаспадар',\n",
       " 'метад',\n",
       " 'шчасце',\n",
       " 'часць',\n",
       " 'кола',\n",
       " 'канал',\n",
       " 'бачыць',\n",
       " 'знаходзяцца',\n",
       " 'практык',\n",
       " 'доктар',\n",
       " 'ранейшы',\n",
       " 'продаж',\n",
       " 'архіў',\n",
       " 'двор',\n",
       " 'праходзіць',\n",
       " 'трэцяе',\n",
       " 'млн',\n",
       " 'адносна',\n",
       " 'штаны',\n",
       " 'полацкі',\n",
       " 'паважаны',\n",
       " 'усход',\n",
       " 'перайсці',\n",
       " 'англійскі',\n",
       " 'праваабарончы',\n",
       " 'мама',\n",
       " 'паўстанне',\n",
       " 'багаты',\n",
       " 'апісанне',\n",
       " 'вкл',\n",
       " 'карысны',\n",
       " 'налада',\n",
       " 'ордэн',\n",
       " 'гімназія',\n",
       " 'неабходнасць',\n",
       " 'глыбокі',\n",
       " 'рэлігійны',\n",
       " 'альтэрнатыва',\n",
       " 'захаванне',\n",
       " 'даць',\n",
       " 'медыцынскі',\n",
       " 'буда',\n",
       " 'памылка',\n",
       " 'камень',\n",
       " 'самай',\n",
       " 'гандаль',\n",
       " 'статус',\n",
       " 'каледж',\n",
       " 'перадача',\n",
       " 'выхаванне',\n",
       " 'прыйшоў',\n",
       " 'украінскі',\n",
       " 'якімі',\n",
       " 'ліцэнзія',\n",
       " 'назад',\n",
       " 'відаць',\n",
       " ...]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ffb10e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vecattr(\"чарадзей\", \"count\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
