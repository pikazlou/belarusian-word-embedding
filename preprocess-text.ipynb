{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee354c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from gensim import utils\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_short, strip_numeric, strip_multiple_whitespaces, remove_stopwords\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import lzma\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f9425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logging initialized\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, force = True)\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Logging initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7323d960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GrammarDB.zip', <http.client.HTTPMessage at 0x174864150>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Link found here: https://metatext.io/datasets/cc100-belarusian\n",
    "urllib.request.urlretrieve('https://data.statmt.org/cc-100/be.txt.xz', \n",
    "                           'be.txt.xz')\n",
    "\n",
    "urllib.request.urlretrieve('https://github.com/Belarus/GrammarDB/archive/refs/tags/PUBLICATION_2021.zip', \n",
    "                           'GrammarDB.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961a014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lzma.open(\"be.txt.xz\", \"rb\") as fsrc:\n",
    "    with open(\"be.txt\", \"wb\") as fdst:\n",
    "        shutil.copyfileobj(fsrc, fdst)\n",
    "\n",
    "with zipfile.ZipFile('GrammarDB.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5a50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "from itertools import islice\n",
    "\n",
    "def calculate_mapping_from_forms_to_base(filepath, tag_prefixes=[]):\n",
    "    xml_doc = xml.dom.minidom.parse(filepath)\n",
    "    paradigms = xml_doc.getElementsByTagName('Paradigm')\n",
    "    result = {}\n",
    "    collision_count = 0\n",
    "    collisions = set()\n",
    "    for paradigm in paradigms:\n",
    "        tag = paradigm.getAttribute('tag')\n",
    "        if len(tag_prefixes) == 0 or any([tag.startswith(p) for p in tag_prefixes]):\n",
    "            variants = paradigm.getElementsByTagName('Variant')\n",
    "            for variant in variants:\n",
    "                base = variant.getAttribute('lemma').replace(\"+\", \"\").lower()\n",
    "                if base not in BASE_FORM_BLACKLIST:\n",
    "                    forms = variant.getElementsByTagName('Form')\n",
    "                    local_map = {}\n",
    "                    citation_count = max([form.getAttribute('slouniki').count(',') for form in forms]) + 1\n",
    "                    for form in forms:\n",
    "                        if len(form.childNodes) > 0:\n",
    "                            word = form.childNodes[0].data.replace(\"+\", \"\").lower()\n",
    "                            local_map[word] = (base, citation_count)\n",
    "                    for k, v in local_map.items():\n",
    "                        if k in result:\n",
    "                            if result[k][1] == v[1] and result[k][0] != v[0]:\n",
    "                                collision_count += 1\n",
    "                                collisions.add(v[0])\n",
    "                                collisions.add(result[k][0])\n",
    "                            elif result[k][1] < v[1]:\n",
    "                                result[k] = v\n",
    "                        else:\n",
    "                            result[k] = v\n",
    "                    \n",
    "    logger.info(f\"Collisions (forms leading to different base word, and having same amount of citation): {collision_count}\")\n",
    "    logger.info(f\"Examples of collisions: {list(islice(collisions, 5))}\")\n",
    "    for k in result:\n",
    "        result[k] = result[k][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9344cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FORM_BLACKLIST = [\n",
    "    'як' # can mean 'bull', but mostly used as particle \n",
    "] + [chr(ord('а')+delta) for delta in range(0, 32)] # alphabet letters\n",
    "\n",
    "DERIVED_FORM_BLACKLIST = [\n",
    "    'але', # can mean geographic place 'Ала', but mostly used as particle 'але'\n",
    "    'калі', # weird form of 'калій' - 'каль', but used as particle 'калі'\n",
    "    'вось', # can mean 'axis', but mostly used as particle\n",
    "    'нам', # can mean short form of 'намеснік', but mostly used as pronoun 'мы'\n",
    "    'наша', # some weird noun 'наша', but mostly used as pronoun 'мы'\n",
    "    'нашы', # can be used as noun, but motly used as pronoun 'мы'\n",
    "    'яму' # can be used as rare noun 'ям', but mostly used as pronoun 'ён'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8683796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 2597\n",
      "INFO:root:Examples of collisions: ['абвадніць', 'загануць', 'перапрызначыцца', 'абучыцца', 'прывучыць']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 33\n",
      "INFO:root:Examples of collisions: ['герцэгавіна', 'палестына', 'палесціна', 'полацак', 'днепр']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 1345\n",
      "INFO:root:Examples of collisions: ['гумоз', 'залогадавец', 'валок', 'забел', 'гурыец']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 1155\n",
      "INFO:root:Examples of collisions: ['наркот', 'паўднёвец', 'пыха', 'ляха', 'махор']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 954\n",
      "INFO:root:Examples of collisions: ['ранне', 'учын', 'страха', 'рубка', 'фарманта']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 51\n",
      "INFO:root:Examples of collisions: ['крэчатавы', 'вітавы', 'дугласавы', 'дугласаў', 'дакалумбаў']\n",
      "INFO:root:Collisions (forms leading to different base word, and having same amount of citation): 37\n",
      "INFO:root:Examples of collisions: ['чыжовы', 'шчупакоў', 'чэпікавы', 'шчупаковы', 'чыжоў']\n"
     ]
    }
   ],
   "source": [
    "#verbs\n",
    "v = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/V.xml')\n",
    "\n",
    "#proper nouns\n",
    "nprop = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/NP.xml', ['NPII'])\n",
    "\n",
    "#nouns\n",
    "n1 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N1.xml')\n",
    "n2 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N2.xml')\n",
    "n3 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/N3.xml')\n",
    "\n",
    "#adjectives\n",
    "adj1 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/A1.xml', ['ARP', 'AQP'])\n",
    "adj2 = calculate_mapping_from_forms_to_base('GrammarDB-PUBLICATION_2021/A2.xml', ['ARP', 'AQP'])\n",
    "\n",
    "WORD_MAP = {}\n",
    "WORD_MAP.update(v)\n",
    "WORD_MAP.update(nprop)\n",
    "WORD_MAP.update(n1)\n",
    "WORD_MAP.update(n2)\n",
    "WORD_MAP.update(n3)\n",
    "WORD_MAP.update(adj1)\n",
    "WORD_MAP.update(adj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cc6c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262675\n",
      "рух\n",
      "беларусь\n"
     ]
    }
   ],
   "source": [
    "print(len(WORD_MAP))\n",
    "print(WORD_MAP['рухам'])\n",
    "print(WORD_MAP['беларусі'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a196c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_WORD_MAP = {\n",
    "    'людзмі': WORD_MAP['людзьмі'],\n",
    "    'расеі': WORD_MAP['расіі'],\n",
    "    'расея': 'расія',\n",
    "    'расею': WORD_MAP['расію'],\n",
    "    'расеяй': WORD_MAP['расіяй'],\n",
    "    'ссср': 'ссср',\n",
    "    'бсср': 'бсср',\n",
    "    'бнр': 'бнр',\n",
    "    'вкл': 'вкл',\n",
    "    'смі': 'смі',\n",
    "    'шоў': 'шоў',\n",
    "    'тыс': 'тысяча',\n",
    "    'млн': 'мільён',\n",
    "    'вул': 'вуліца',\n",
    "    'вобл': 'вобласць',\n",
    "    'тэл': 'тэлефон',\n",
    "    'км': WORD_MAP['кіламетр'],\n",
    "    'навінаў': WORD_MAP['навін'],\n",
    "    'тысячаў': WORD_MAP['тысяч'],\n",
    "    'прэзыдэнта': WORD_MAP['прэзідэнта'],\n",
    "    'прэзыдэнт': WORD_MAP['прэзідэнт'],\n",
    "    'камэнтары': WORD_MAP['каментары'],\n",
    "    'сыстэму': WORD_MAP['сістэму'],\n",
    "    'сытуацыі': WORD_MAP['сітуацыі'],\n",
    "    'сытуацыя': WORD_MAP['сітуацыя'],\n",
    "    'цэнтар': WORD_MAP['цэнтр'],\n",
    "    'вільня': WORD_MAP['вільнюс'],\n",
    "    'вільню': WORD_MAP['вільнюс'],\n",
    "    'сьмерці': WORD_MAP['смерці'],\n",
    "    'грамадзтва': WORD_MAP['грамадства'],\n",
    "    'эўропы': WORD_MAP['еўропы'],\n",
    "    'сябраў': WORD_MAP['сяброў'],\n",
    "    'апазыцыі': WORD_MAP['апазіцыі'],\n",
    "    'міністар': WORD_MAP[\"міністр\"],\n",
    "    'спэцыяльныя': WORD_MAP[\"спецыяльныя\"],\n",
    "    'мэню': WORD_MAP[\"меню\"],\n",
    "    'інтэрвію': WORD_MAP[\"інтэрв'ю\"],\n",
    "    'газэты': WORD_MAP[\"газеты\"],\n",
    "    'дакумэнты': WORD_MAP[\"дакументы\"],\n",
    "    'сытуацыю': WORD_MAP[\"сітуацыю\"],\n",
    "    'разьдзел': WORD_MAP[\"раздзел\"],\n",
    "    'сьмерць': WORD_MAP[\"смерць\"],\n",
    "    'грамадзкі': WORD_MAP[\"грамадскі\"],\n",
    "    'калёніі': WORD_MAP[\"калоніі\"],\n",
    "    'газэта': WORD_MAP[\"газета\"],\n",
    "}\n",
    "WORD_MAP.update(MANUAL_WORD_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aeb2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_trailing_newline(iterable):\n",
    "    for i in iterable:\n",
    "        yield i.rstrip()\n",
    "\n",
    "# this function is based on gensim.parser.preprocessing.strip_punctuation\n",
    "# we replace gensim's version to correctly handle symbol ' in words, such as п'еса or кар'ера\n",
    "RE_PUNCTUATION = re.compile(r'([%s])+' % re.escape(string.punctuation.replace(\"'\",\"\")), re.UNICODE)\n",
    "def strip_punctuation(s):\n",
    "    s = utils.to_unicode(s)\n",
    "    return RE_PUNCTUATION.sub(\" \", s)\n",
    "\n",
    "CHARACTERS_MAP = {'’': '\\'', 'ý': 'ў', ' ў': ' у', 'i': 'і', 'ньн': 'нн', 'цьц': 'цц', 'сьц': 'сц', 'сьл':'сл', 'дзьдз': 'ддз', 'сьв': 'св', 'зьв': 'зв', 'сьп': 'сп', 'сьс': 'сс', 'сьн': 'сн', 'зьм': 'зм', 'зьн': 'зн', 'зьл': 'зл'}\n",
    "def lower_and_replace_characters(iterable):\n",
    "    for s in iterable:\n",
    "        s = s.lower()\n",
    "        for k, v in CHARACTERS_MAP.items():\n",
    "            s = s.replace(k, v)\n",
    "        yield s\n",
    "\n",
    "def split_sentences(iterable):\n",
    "    for i in iterable:\n",
    "        merged_dots = re.sub(\"[\\.]+\", \".\", i)\n",
    "        sentences = merged_dots.split('.')\n",
    "        for s in sentences:\n",
    "            yield s\n",
    "\n",
    "def process_and_filter_word(raw_words):\n",
    "    valid_words = []\n",
    "    removed_words = []\n",
    "    for w in raw_words:\n",
    "        w = w.strip(\"'\")\n",
    "        if w in WORD_MAP:\n",
    "            valid_words.append(WORD_MAP[w])\n",
    "        else:\n",
    "            removed_words.append(w)\n",
    "    return (valid_words, removed_words)\n",
    "\n",
    "global_removed_words = []\n",
    "def preprocess_sentences(iterable):\n",
    "    for i in iterable:\n",
    "        s = strip_multiple_whitespaces(strip_numeric(strip_short(strip_punctuation(i))))\n",
    "        s = re.sub(\"[«»“”„…—°′²]\", \"\", s)\n",
    "        s = remove_stopwords(s, stopwords=DERIVED_FORM_BLACKLIST)\n",
    "        valid_words, removed_words = process_and_filter_word(s.split())\n",
    "        s = ' '.join(valid_words)\n",
    "        global_removed_words.extend(removed_words)\n",
    "        yield s\n",
    "\n",
    "def remove_short_lines(iterable):\n",
    "    for i in iterable:\n",
    "        if not i.isspace() and len(i) >= 20:\n",
    "            yield i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('be.txt', 'r') as original_file:\n",
    "    with open('processed-corpus.txt', 'w') as sentences_file:\n",
    "        with open('removed-words.txt', 'w') as removed_words_file:\n",
    "            for s in remove_short_lines(preprocess_sentences(split_sentences(lower_and_replace_characters(strip_trailing_newline(original_file))))):\n",
    "                sentences_file.write(s + \"\\n\")\n",
    "                removed_words_file.write(' '.join(global_removed_words) + \"\\n\")\n",
    "                global_removed_words.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
